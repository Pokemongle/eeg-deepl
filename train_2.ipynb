{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2229f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from load_data import MyData  # self-made\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm_notebook as tqdm # View procedure\n",
    "import os\n",
    "import scipy.io\n",
    "from random import random\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from network_cnn_lstm_4 import MyNetwork\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c775b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "C,H,W = 1,1,2400\n",
    "learn_rate = 0.0005\n",
    "num_epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7fcb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "manualSeed = 4\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c40bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda:0\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 定义LSTM超参数\n",
    "input_size = 64  # 输入特征维度\n",
    "hidden_size = 64  # 隐藏单元数量\n",
    "num_layers = 2  # LSTM层数\n",
    "output_size = 2  # 输出类别数量\n",
    "model = MyNetwork(input_size, hidden_size, num_layers, output_size)\n",
    "# # model.load_state_dict(torch.load(\"../model/Trial2.pt\")) # !!!!!!!!!!!!!!!!!!!!!\n",
    "model = model.to(device)\n",
    "\n",
    "# ==损失函数权重\n",
    "# ======== 二分类HC/DOC\n",
    "# 计算总样本数量\n",
    "# condition1\n",
    "# total_samples = 887 + 985 + 879\n",
    "# condition2\n",
    "# total_samples = 929 + 1029 + 886\n",
    "# condition3\n",
    "total_samples = 887 + 975 + 879\n",
    "# 计算每个类别的权重\n",
    "# condition1\n",
    "# weights = [total_samples / 887, total_samples / (985 + 879)]\n",
    "# condition2\n",
    "# weights = [total_samples / 929, total_samples / (1029 + 886)]\n",
    "# condition3\n",
    "weights = [total_samples / 887, total_samples / (975 + 879)]\n",
    "\n",
    "# ======== 二分类MCS/UWS\n",
    "# 计算总样本数量\n",
    "# condition1\n",
    "# total_samples = 985 + 879\n",
    "# condition2\n",
    "# total_samples = 1029 + 886\n",
    "# condition3\n",
    "# total_samples = 975 + 879\n",
    "# 计算每个类别的权重\n",
    "# condition1\n",
    "# weights = [total_samples / 985, total_samples / 879]\n",
    "# condition2\n",
    "# weights = [total_samples / 1029, total_samples / 886]\n",
    "# condition3\n",
    "# weights = [total_samples / 975, total_samples / 879]\n",
    "\n",
    "# # ======== 三分类\n",
    "# # 计算总样本数量\n",
    "# # conditionB\n",
    "# total_samples = 929 + 1029 + 886\n",
    "# # 计算每个类别的权重\n",
    "# # conditionB\n",
    "# weights = [total_samples / 929, total_samples / 1029, total_samples / 886]\n",
    "\n",
    "# 将权重转换为张量\n",
    "weights_tensor = torch.tensor(weights, device=device)\n",
    "\n",
    "# 定义交叉熵损失函数并设置权重\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f278877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f32739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f30e7d743dc45668200137f51469478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/eegmap_split/conditionC\\train\\mcs\\conditionC_mcs_train_3.pt\n",
      "../data/eegmap_split/conditionC\\train\\mcs\\conditionC_mcs_train_3_label.pt\n",
      "../data/eegmap_split/conditionC\\train\\mcs\\conditionC_mcs_val_3.pt\n",
      "../data/eegmap_split/conditionC\\train\\mcs\\conditionC_mcs_val_3_label.pt\n",
      "../data/eegmap_split/conditionC\\train\\uws\\conditionC_uws_train_3.pt\n",
      "../data/eegmap_split/conditionC\\train\\uws\\conditionC_uws_train_3_label.pt\n",
      "../data/eegmap_split/conditionC\\train\\uws\\conditionC_uws_val_3.pt\n",
      "../data/eegmap_split/conditionC\\train\\uws\\conditionC_uws_val_3_label.pt\n",
      "torch.Size([1854, 2400, 10, 11])\n",
      "torch.Size([1854])\n",
      "torch.Size([462, 2400, 10, 11])\n",
      "torch.Size([462])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:220: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10241586c4ee4348abb313d47d88bdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 0 Training =========\n",
      "tensor([[-0.5552, -0.9213]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 115.29502415657043\n",
      "Train steps: 1000, Loss: 0.5267472863197327\n",
      "========= Epoch 0 Testing =========\n",
      "Loss: 70.10761260986328 Accuracy: 0.6200000047683716\n",
      "Loss: 142.20834350585938 Accuracy: 0.5849999785423279\n",
      "Loss: 213.20953369140625 Accuracy: 0.596666693687439\n",
      "Loss: 285.02532958984375 Accuracy: 0.5849999785423279\n",
      "Total Loss: 330.7259826660156 Total Accuracy: 0.5865800976753235\n",
      "..........Saving the model..........\n",
      "========= Epoch 1 Training =========\n",
      "tensor([[ 0.9867, -0.1448]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 297.76302433013916\n",
      "Train steps: 2000, Loss: 0.2795543372631073\n",
      "tensor([[0.9262, 1.2556]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 434.91002464294434\n",
      "Train steps: 3000, Loss: 0.541920006275177\n",
      "========= Epoch 1 Testing =========\n",
      "Loss: 79.12764739990234 Accuracy: 0.5099999904632568\n",
      "Loss: 161.7594757080078 Accuracy: 0.5249999761581421\n",
      "Loss: 236.89793395996094 Accuracy: 0.5266667008399963\n",
      "Loss: 308.8853759765625 Accuracy: 0.5374999642372131\n",
      "Total Loss: 356.8966369628906 Total Accuracy: 0.5173160433769226\n",
      "..........Saving the model..........\n",
      "========= Epoch 2 Training =========\n",
      "tensor([[-0.7980, -0.6539]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 616.6710245609283\n",
      "Train steps: 4000, Loss: 0.623685896396637\n",
      "tensor([[0.3874, 0.3625]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 754.4330565929413\n",
      "Train steps: 5000, Loss: 0.6807780861854553\n",
      "========= Epoch 2 Testing =========\n",
      "Loss: 69.90709686279297 Accuracy: 0.5399999618530273\n",
      "Loss: 141.71458435058594 Accuracy: 0.5049999952316284\n",
      "Loss: 212.73391723632812 Accuracy: 0.5300000309944153\n",
      "Loss: 281.2308349609375 Accuracy: 0.5349999666213989\n",
      "Total Loss: 322.5936584472656 Total Accuracy: 0.5584415793418884\n",
      "..........Saving the model..........\n",
      "========= Epoch 3 Training =========\n",
      "tensor([[-0.7840, -1.2686]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 937.5400569438934\n",
      "Train steps: 6000, Loss: 0.4799114465713501\n",
      "tensor([[-0.1869,  0.3798]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1074.6070563793182\n",
      "Train steps: 7000, Loss: 1.016097068786621\n",
      "========= Epoch 3 Testing =========\n",
      "Loss: 66.51493835449219 Accuracy: 0.6200000047683716\n",
      "Loss: 130.40711975097656 Accuracy: 0.6449999809265137\n",
      "Loss: 196.7039031982422 Accuracy: 0.6333333253860474\n",
      "Loss: 251.488525390625 Accuracy: 0.6474999785423279\n",
      "Total Loss: 282.421630859375 Total Accuracy: 0.6601731777191162\n",
      "..........Saving the model..........\n",
      "========= Epoch 4 Training =========\n",
      "tensor([[-0.7742,  1.6051]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1254.839565038681\n",
      "Train steps: 8000, Loss: 0.088568776845932\n",
      "tensor([[1.4359, 0.1047]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1392.5466270446777\n",
      "Train steps: 9000, Loss: 0.2344062179327011\n",
      "========= Epoch 4 Testing =========\n",
      "Loss: 37.58312225341797 Accuracy: 0.8499999642372131\n",
      "Loss: 92.87133026123047 Accuracy: 0.8199999928474426\n",
      "Loss: 145.58668518066406 Accuracy: 0.8100000023841858\n",
      "Loss: 184.34423828125 Accuracy: 0.8075000047683716\n",
      "Total Loss: 216.84498596191406 Total Accuracy: 0.8030303120613098\n",
      "..........Saving the model..........\n",
      "========= Epoch 5 Training =========\n",
      "tensor([[ 0.4747, -2.4689]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1573.1956272125244\n",
      "Train steps: 10000, Loss: 0.05133398249745369\n",
      "tensor([[ 1.9566, -4.9192]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1710.8646259307861\n",
      "Train steps: 11000, Loss: 0.0010319390567019582\n",
      "========= Epoch 5 Testing =========\n",
      "Loss: 31.96730613708496 Accuracy: 0.8700000047683716\n",
      "Loss: 49.697452545166016 Accuracy: 0.8999999761581421\n",
      "Loss: 79.56449890136719 Accuracy: 0.9000000357627869\n",
      "Loss: 97.56684875488281 Accuracy: 0.8974999785423279\n",
      "Total Loss: 111.99842071533203 Total Accuracy: 0.8961039185523987\n",
      "..........Saving the model..........\n",
      "========= Epoch 6 Training =========\n",
      "tensor([[-7.5776,  8.2516]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1894.6516518592834\n",
      "Train steps: 12000, Loss: 1.1920928244535389e-07\n",
      "========= Epoch 6 Testing =========\n",
      "Loss: 85.35472869873047 Accuracy: 0.7099999785423279\n",
      "Loss: 151.68040466308594 Accuracy: 0.7450000047683716\n",
      "Loss: 221.25665283203125 Accuracy: 0.75\n",
      "Loss: 276.5005187988281 Accuracy: 0.7649999856948853\n",
      "Total Loss: 326.2594299316406 Total Accuracy: 0.7683982849121094\n",
      "..........Saving the model..........\n",
      "========= Epoch 7 Training =========\n",
      "tensor([[-9.3405,  1.4587]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2077.807650089264\n",
      "Train steps: 13000, Loss: 2.038458114839159e-05\n",
      "tensor([[10.7707, -1.8011]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2215.170651912689\n",
      "Train steps: 14000, Loss: 3.4570634852570947e-06\n",
      "========= Epoch 7 Testing =========\n",
      "Loss: 25.583999633789062 Accuracy: 0.9099999666213989\n",
      "Loss: 54.826255798339844 Accuracy: 0.9049999713897705\n",
      "Loss: 107.91352081298828 Accuracy: 0.8966667056083679\n",
      "Loss: 159.8998260498047 Accuracy: 0.875\n",
      "Total Loss: 216.85321044921875 Total Accuracy: 0.8658008575439453\n",
      "..........Saving the model..........\n",
      "========= Epoch 8 Training =========\n",
      "tensor([[-4.4732,  2.6190]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2399.4916508197784\n",
      "Train steps: 15000, Loss: 0.0008312584250234067\n",
      "tensor([[ 4.4438, -2.0409]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2536.7446773052216\n",
      "Train steps: 16000, Loss: 0.0015254301251843572\n",
      "========= Epoch 8 Testing =========\n",
      "Loss: 77.49016571044922 Accuracy: 0.75\n",
      "Loss: 133.122802734375 Accuracy: 0.7899999618530273\n",
      "Loss: 167.16952514648438 Accuracy: 0.8233333826065063\n",
      "Loss: 225.59335327148438 Accuracy: 0.824999988079071\n",
      "Total Loss: 244.77099609375 Total Accuracy: 0.8354978561401367\n",
      "..........Saving the model..........\n",
      "========= Epoch 9 Training =========\n",
      "tensor([[ 2.7210, -2.0167]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2720.2886753082275\n",
      "Train steps: 17000, Loss: 0.008720293641090393\n",
      "tensor([[-10.7887,  -1.1989]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2858.05193400383\n",
      "Train steps: 18000, Loss: 6.842378934379667e-05\n",
      "========= Epoch 9 Testing =========\n",
      "Loss: 17.887752532958984 Accuracy: 0.9300000071525574\n",
      "Loss: 32.65998077392578 Accuracy: 0.9350000023841858\n",
      "Loss: 43.66947937011719 Accuracy: 0.9399999976158142\n",
      "Loss: 70.05501556396484 Accuracy: 0.9350000023841858\n",
      "Total Loss: 78.53846740722656 Total Accuracy: 0.9372294545173645\n",
      "..........Saving the model..........\n",
      "========= Epoch 10 Training =========\n",
      "tensor([[11.8800, -4.3715]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3042.0089337825775\n",
      "Train steps: 19000, Loss: 1.1920928244535389e-07\n",
      "tensor([[-10.8891,   5.3614]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3179.260954618454\n",
      "Train steps: 20000, Loss: 1.1920928244535389e-07\n",
      "========= Epoch 10 Testing =========\n",
      "Loss: 11.881448745727539 Accuracy: 0.9599999785423279\n",
      "Loss: 21.506614685058594 Accuracy: 0.9549999833106995\n",
      "Loss: 36.379817962646484 Accuracy: 0.9466667175292969\n",
      "Loss: 55.75580978393555 Accuracy: 0.9375\n",
      "Total Loss: 70.56837463378906 Total Accuracy: 0.9350649118423462\n",
      "..........Saving the model..........\n",
      "========= Epoch 11 Training =========\n",
      "tensor([[-11.6758,   3.9708]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3361.8319566249847\n",
      "Train steps: 21000, Loss: 1.1920928244535389e-07\n",
      "tensor([[-13.9102,   1.7693]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3500.1919543743134\n",
      "Train steps: 22000, Loss: 1.1920928244535389e-07\n",
      "========= Epoch 11 Testing =========\n",
      "Loss: 23.387975692749023 Accuracy: 0.9399999976158142\n",
      "Loss: 48.12974166870117 Accuracy: 0.9199999570846558\n",
      "Loss: 71.43608093261719 Accuracy: 0.9266666769981384\n",
      "Loss: 84.48922729492188 Accuracy: 0.9300000071525574\n",
      "Total Loss: 101.8565902709961 Total Accuracy: 0.9285714030265808\n",
      "..........Saving the model..........\n",
      "========= Epoch 12 Training =========\n",
      "tensor([[10.1096, -4.5832]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3683.7749783992767\n",
      "Train steps: 23000, Loss: 3.576278118089249e-07\n",
      "tensor([[17.1416, -1.1206]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3820.8239781856537\n",
      "Train steps: 24000, Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 12 Testing =========\n",
      "Loss: 30.319580078125 Accuracy: 0.8999999761581421\n",
      "Loss: 52.6852912902832 Accuracy: 0.9249999523162842\n",
      "Loss: 68.60873413085938 Accuracy: 0.9266666769981384\n",
      "Loss: 109.05279541015625 Accuracy: 0.9199999570846558\n",
      "Total Loss: 116.57205963134766 Total Accuracy: 0.9220778942108154\n",
      "..........Saving the model..........\n",
      "========= Epoch 13 Training =========\n",
      "tensor([[-3.4159,  6.9253]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4004.3219785690308\n",
      "Train steps: 25000, Loss: 3.2305197237292305e-05\n",
      "========= Epoch 13 Testing =========\n",
      "Loss: 16.27914810180664 Accuracy: 0.9399999976158142\n",
      "Loss: 53.95633316040039 Accuracy: 0.9149999618530273\n",
      "Loss: 72.8160171508789 Accuracy: 0.9166666865348816\n",
      "Loss: 90.20626068115234 Accuracy: 0.9199999570846558\n",
      "Total Loss: 108.99339294433594 Total Accuracy: 0.9199134111404419\n",
      "..........Saving the model..........\n",
      "========= Epoch 14 Training =========\n",
      "tensor([[-11.4504,  -3.1987]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4186.526978492737\n",
      "Train steps: 26000, Loss: 0.00026079590315930545\n",
      "tensor([[-14.8408,   7.0088]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4321.410000324249\n",
      "Train steps: 27000, Loss: 0.0\n",
      "========= Epoch 14 Testing =========\n",
      "Loss: 18.26181983947754 Accuracy: 0.9300000071525574\n",
      "Loss: 45.70846939086914 Accuracy: 0.9300000071525574\n",
      "Loss: 87.65824890136719 Accuracy: 0.9166666865348816\n",
      "Loss: 137.54029846191406 Accuracy: 0.9099999666213989\n",
      "Total Loss: 177.51670837402344 Total Accuracy: 0.9025974273681641\n",
      "..........Saving the model..........\n",
      "========= Epoch 15 Training =========\n",
      "tensor([[-12.8286,   1.7866]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4501.6770005226135\n",
      "Train steps: 28000, Loss: 4.768370445162873e-07\n",
      "tensor([[12.3876,  4.1458]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4637.169000387192\n",
      "Train steps: 29000, Loss: 0.00026341783814132214\n",
      "========= Epoch 15 Testing =========\n",
      "Loss: 10.267158508300781 Accuracy: 0.9599999785423279\n",
      "Loss: 17.196510314941406 Accuracy: 0.9549999833106995\n",
      "Loss: 30.49357795715332 Accuracy: 0.9566667079925537\n",
      "Loss: 53.375667572021484 Accuracy: 0.9449999928474426\n",
      "Total Loss: 68.29421997070312 Total Accuracy: 0.9458874464035034\n",
      "..........Saving the model..........\n",
      "========= Epoch 16 Training =========\n",
      "tensor([[-6.6449,  4.3421]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4817.52100110054\n",
      "Train steps: 30000, Loss: 1.6927575416048057e-05\n",
      "tensor([[-6.4526,  7.1853]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4953.350029468536\n",
      "Train steps: 31000, Loss: 1.1920922133867862e-06\n",
      "========= Epoch 16 Testing =========\n",
      "Loss: 33.532100677490234 Accuracy: 0.9099999666213989\n",
      "Loss: 56.958518981933594 Accuracy: 0.9300000071525574\n",
      "Loss: 81.99951171875 Accuracy: 0.9233333468437195\n",
      "Loss: 107.11052703857422 Accuracy: 0.9099999666213989\n",
      "Total Loss: 112.59449005126953 Total Accuracy: 0.9177489280700684\n",
      "..........Saving the model..........\n",
      "========= Epoch 17 Training =========\n",
      "tensor([[-10.2090,   3.7121]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 5133.591539144516\n",
      "Train steps: 32000, Loss: 9.536738616588991e-07\n"
     ]
    }
   ],
   "source": [
    "# experimental dir: rest, conditionA, conditionB, conditionC\n",
    "# exper_dir = \"rest\"\n",
    "exper_dir = \"conditionC\"\n",
    "root_dir = f\"../data/eegmap_split/{exper_dir}\"\n",
    "classification = \"mcs_uws\"\n",
    "fold_num = 1\n",
    "for fold in tqdm(range(fold_num)):\n",
    "    # train num folds\n",
    "    fold = 3\n",
    "    # -- prepare datasets\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "#     # ---- hc\n",
    "#     dataset = MyData(root_dir, \"train\", \"hc\") # hc\n",
    "#     # find the fold file\n",
    "#     count = 0\n",
    "#     for person in range(len(dataset)):\n",
    "#         filename = os.path.join(dataset.path, dataset.file_path[person])\n",
    "#         # extract the pure name of the file\n",
    "#         parts = filename.split(\"\\\\\")\n",
    "#         file_name = parts[-1]\n",
    "#         name_without_extension = file_name.split(\".\")[0]\n",
    "#         # label or data\n",
    "#         file_last = name_without_extension.split(\"_\")[-1]\n",
    "#         if file_last.isdigit(): # data\n",
    "#             # is this fold or not\n",
    "#             if int(file_last) == fold: # yes\n",
    "#                 print(filename)\n",
    "#                 count = count + 1\n",
    "#                 data_map = torch.load(filename)\n",
    "#                 # train or valid\n",
    "#                 if name_without_extension.split(\"_\")[-2] == \"train\":\n",
    "#                     for i in range(data_map.size(0)):\n",
    "#                         train_data.append(data_map[i])\n",
    "#                 elif name_without_extension.split(\"_\")[-2] == \"val\":\n",
    "#                     for i in range(data_map.size(0)):\n",
    "#                         test_data.append(data_map[i])\n",
    "#                 if count == 4:\n",
    "#                     del data_map\n",
    "#                     gc.collect()\n",
    "#                     torch.cuda.empty_cache() \n",
    "#                     break\n",
    "#             else:   # not\n",
    "#                 pass\n",
    "#         else: # label\n",
    "#             # is this fold or not\n",
    "#             file_last = name_without_extension.split(\"_\")[-2]\n",
    "#             if int(file_last) == fold: # yes\n",
    "#                 print(filename)\n",
    "#                 count = count + 1\n",
    "#                 data_map = torch.load(filename)\n",
    "#                 # train or valid\n",
    "#                 if name_without_extension.split(\"_\")[-3] == \"train\":\n",
    "#                     for i in range(data_map.size(0)):\n",
    "#                         train_label.append(data_map[i])\n",
    "#                 elif name_without_extension.split(\"_\")[-3] == \"val\":\n",
    "#                     for i in range(data_map.size(0)):\n",
    "#                         test_label.append(data_map[i])\n",
    "#                 if count == 4:\n",
    "#                     del data_map\n",
    "#                     gc.collect()\n",
    "#                     torch.cuda.empty_cache() \n",
    "#                     break\n",
    "#             else:   # not\n",
    "#                 pass\n",
    "#         del filename, parts, file_name, name_without_extension, file_last\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()    \n",
    "    # ---- mcs\n",
    "    dataset = MyData(root_dir, \"train\", \"mcs\") # mcs\n",
    "    # find the fold file\n",
    "    count = 0\n",
    "    for person in range(len(dataset)):\n",
    "        filename = os.path.join(dataset.path, dataset.file_path[person])\n",
    "        # extract the pure name of the file\n",
    "        parts = filename.split(\"\\\\\")\n",
    "        file_name = parts[-1]\n",
    "        name_without_extension = file_name.split(\".\")[0]\n",
    "        # label or data\n",
    "        file_last = name_without_extension.split(\"_\")[-1]\n",
    "        if file_last.isdigit(): # data\n",
    "            # is this fold or not\n",
    "            if int(file_last) == fold: # yes\n",
    "                print(filename)\n",
    "                count = count + 1\n",
    "                data_map = torch.load(filename)\n",
    "                # train or valid\n",
    "                if name_without_extension.split(\"_\")[-2] == \"train\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        train_data.append(data_map[i])\n",
    "                elif name_without_extension.split(\"_\")[-2] == \"val\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        test_data.append(data_map[i])\n",
    "                if count == 4:\n",
    "                    del data_map\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache() \n",
    "                    break\n",
    "            else:   # not\n",
    "                pass\n",
    "        else: # label\n",
    "            # is this fold or not\n",
    "            file_last = name_without_extension.split(\"_\")[-2]\n",
    "            if int(file_last) == fold: # yes\n",
    "                print(filename)\n",
    "                count = count + 1\n",
    "                data_map = torch.load(filename)\n",
    "                # train or valid\n",
    "                if name_without_extension.split(\"_\")[-3] == \"train\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        train_label.append(data_map[i])\n",
    "                elif name_without_extension.split(\"_\")[-3] == \"val\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        test_label.append(data_map[i])\n",
    "                if count == 4:\n",
    "                    del data_map\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache() \n",
    "                    break\n",
    "            else:   # not\n",
    "                pass\n",
    "        del filename, parts, file_name, name_without_extension, file_last\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()    \n",
    "    # ---- uws\n",
    "    dataset = MyData(root_dir, \"train\", \"uws\") # uws\n",
    "    # find the fold file\n",
    "    count = 0\n",
    "    for person in range(len(dataset)):\n",
    "        filename = os.path.join(dataset.path, dataset.file_path[person])\n",
    "        # extract the pure name of the file\n",
    "        parts = filename.split(\"\\\\\")\n",
    "        file_name = parts[-1]\n",
    "        name_without_extension = file_name.split(\".\")[0]\n",
    "        # label or data\n",
    "        file_last = name_without_extension.split(\"_\")[-1]\n",
    "        if file_last.isdigit(): # data\n",
    "            # is this fold or not\n",
    "            if int(file_last) == fold: # yes\n",
    "                print(filename)\n",
    "                count = count + 1\n",
    "                data_map = torch.load(filename)\n",
    "                # train or valid\n",
    "                if name_without_extension.split(\"_\")[-2] == \"train\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        train_data.append(data_map[i])\n",
    "                elif name_without_extension.split(\"_\")[-2] == \"val\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        test_data.append(data_map[i])\n",
    "                if count == 4:\n",
    "                    del data_map\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache() \n",
    "                    break\n",
    "            else:   # not\n",
    "                pass\n",
    "        else: # label\n",
    "            # is this fold or not\n",
    "            file_last = name_without_extension.split(\"_\")[-2]\n",
    "            if int(file_last) == fold: # yes\n",
    "                print(filename)\n",
    "                count = count + 1\n",
    "                data_map = torch.load(filename)\n",
    "                # train or valid\n",
    "                if name_without_extension.split(\"_\")[-3] == \"train\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        train_label.append(data_map[i])\n",
    "                elif name_without_extension.split(\"_\")[-3] == \"val\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        test_label.append(data_map[i])\n",
    "                if count == 4:\n",
    "                    del data_map\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache() \n",
    "                    break\n",
    "            else:   # not\n",
    "                pass \n",
    "        del filename, parts, file_name, name_without_extension, file_last\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()    \n",
    "    print(torch.stack(train_data).size())\n",
    "    print(torch.stack(train_label).size())\n",
    "    print(torch.stack(test_data).size())\n",
    "    print(torch.stack(test_label).size())\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "    \n",
    "    train_data = torch.stack(train_data)\n",
    "    train_label = torch.stack(train_label)\n",
    "    test_data = torch.stack(test_data)\n",
    "    test_label = torch.stack(test_label)\n",
    "    # train dataset\n",
    "    train_td = TensorDataset(train_data, train_label)\n",
    "    train_loader = DataLoader(train_td, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    # test dataset\n",
    "    test_td = TensorDataset(test_data, test_label)\n",
    "    test_loader = DataLoader(test_td, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    del train_data, train_label, test_data, test_label, train_td, test_td\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # set mode for each fold\n",
    "    model = MyNetwork(input_size, hidden_size, num_layers, output_size)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learn_rate)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40, 60], gamma=0.2)\n",
    "    # -- start training\n",
    "    start_time = time.time()\n",
    "    # train and test step records\n",
    "    total_train_step = 0\n",
    "    total_test_step = 0\n",
    "    min_test_loss = 1000\n",
    "    # add Tensorboard\n",
    "    writer_train = SummaryWriter(f\"../logs/{classification}/{exper_dir}_CNN_spa_lstm/logs_train_{fold}\")\n",
    "    writer_valid = SummaryWriter(f\"../logs/{classification}/{exper_dir}_CNN_spa_lstm/logs_valid_{fold}\")\n",
    "    writer_valid_acc = SummaryWriter(f\"../logs/{classification}/{exper_dir}_CNN_spa_lstm/logs_valid_acc_{fold}\")\n",
    "    for i in tqdm(range(num_epochs)):  \n",
    "        print(f\"========= Epoch {i} Training =========\")\n",
    "        # train steps\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            # x, y\n",
    "            data_map, label=data\n",
    "            data_map_reshaped = torch.reshape(data_map, (110, 1, 1, 2400))\n",
    "            label_int = label.long()\n",
    "            data_map_reshaped=data_map_reshaped.to(device)\n",
    "            label_int=label_int.to(device)\n",
    "            del data_map, label\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # y_pred\n",
    "            label_pred = model(data_map_reshaped)\n",
    "            # Loss Computation and Optimization\n",
    "            loss = criterion(label_pred,label_int)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # draw tensorboard\n",
    "            total_train_step = total_train_step + 1\n",
    "            # print info\n",
    "            if total_train_step % 1000 == 0:\n",
    "                end_time = time.time()\n",
    "                print(label_pred)\n",
    "                print(f\"Train time: {end_time - start_time}\")\n",
    "                print(f\"Train steps: {total_train_step}, Loss: {loss.item()}\")\n",
    "            writer_train.add_scalar(\"train_loss\",loss.item(),total_train_step)\n",
    "            # Clear gpu\n",
    "            del data, data_map_reshaped, label_int, label_pred, loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Evaluation and save the best model\n",
    "        print(f\"========= Epoch {i} Testing =========\")\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        test_count = 0\n",
    "        total_test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                test_count = test_count + 1\n",
    "                # x, y\n",
    "                data_map, label=data\n",
    "                data_map_reshaped = torch.reshape(data_map, (110, 1, 1, 2400))\n",
    "                label_int = label.long()\n",
    "                data_map_reshaped = data_map_reshaped.to(device)\n",
    "                label_int = label_int.to(device)\n",
    "                del data_map, label\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                # y_pred\n",
    "                label_pred_test = model(data_map_reshaped)\n",
    "                loss = criterion(label_pred_test,label_int)\n",
    "#                 print(label_pred_test)\n",
    "                # accuracy \n",
    "                total_test_acc = total_test_acc + ((label_pred_test.argmax(1)) == label_int).sum()\n",
    "                # draw tensorboad\n",
    "                total_test_loss = total_test_loss + loss\n",
    "                if test_count % 100 == 0:\n",
    "                    print(f\"Loss: {total_test_loss} Accuracy: {total_test_acc/test_count}\")\n",
    "                # Clear gpu\n",
    "                del data_map_reshaped, label_int, label_pred_test, loss, data\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "        print(f\"Total Loss: {total_test_loss} Total Accuracy: {total_test_acc/test_count}\")\n",
    "        writer_valid.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "        writer_valid_acc.add_scalar(\"test_acc\", total_test_acc/test_count, total_test_step)\n",
    "        total_test_step = total_test_step + 1\n",
    "        print(\"..........Saving the model..........\")\n",
    "        torch.save(model.state_dict(),f\"../model/{classification}/{exper_dir}_CNN_spa_lstm/Fold{fold}_Epoch{i}.pt\") \n",
    "#         if total_test_loss < min_test_loss:\n",
    "#             min_test_loss = total_test_loss\n",
    "#             print(\"..........Saving the model..........\")\n",
    "#             torch.save(model.state_dict(),f\"../model/{exper_dir}/Fold{fold}_Epoch{i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099a8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
