{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2229f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from load_data import MyData  # self-made\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm_notebook as tqdm # View procedure\n",
    "import os\n",
    "import scipy.io\n",
    "from random import random\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from net_cnn_lstm1 import MyNetwork\n",
    "from torchnlp.word_to_vector import GloVe\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c775b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "C,H,W = 1,1,2400\n",
    "learn_rate = 0.0005\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fcb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "manualSeed = 32\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c40bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda:0\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ==损失函数权重\n",
    "# ======== 二分类HC/DOC\n",
    "# 计算总样本数量\n",
    "# condition1\n",
    "# total_samples = 887 + 985 + 879\n",
    "# condition2\n",
    "# total_samples = 929 + 1029 + 886\n",
    "# condition3\n",
    "# total_samples = 887 + 975 + 879\n",
    "# rest\n",
    "total_samples = 852 + 1051 + 872\n",
    "# 计算每个类别的权重\n",
    "# condition1\n",
    "# weights = [total_samples / 887, total_samples / (985 + 879)]\n",
    "# condition2\n",
    "# weights = [total_samples / 929, total_samples / (1029 + 886)]\n",
    "# condition3\n",
    "weights = [total_samples / 852, total_samples / (1051 + 872)]\n",
    "\n",
    "# ======== 二分类MCS/UWS\n",
    "# 计算总样本数量\n",
    "# condition1\n",
    "# total_samples = 985 + 879\n",
    "# condition2\n",
    "# total_samples = 1029 + 886\n",
    "# condition3\n",
    "# total_samples = 975 + 879\n",
    "# rest\n",
    "# total_samples = 1051 + 872\n",
    "# 计算每个类别的权重\n",
    "# condition1\n",
    "# weights = [total_samples / 985, total_samples / 879]\n",
    "# condition2\n",
    "# weights = [total_samples / 1029, total_samples / 886]\n",
    "# condition3\n",
    "# weights = [total_samples / 975, total_samples / 879]\n",
    "# condition3\n",
    "# weights = [total_samples / 1051, total_samples / 872]\n",
    "# 将权重转换为张量\n",
    "weights_tensor = torch.tensor(weights, device=device)\n",
    "\n",
    "# 定义交叉熵损失函数并设置权重\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f32739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:92: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab83fd303344302912d78732c9f2fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/eegmap_split/rest\\train\\mcs\\rest_mcs_train_0.pt\n",
      "../data/eegmap_split/rest\\train\\mcs\\rest_mcs_train_0_mcs_uws_label.pt\n",
      "../data/eegmap_split/rest\\test\\mcs\\rest_mcs_test_0.pt\n",
      "../data/eegmap_split/rest\\test\\mcs\\rest_mcs_test_0_mcs_uws_label.pt\n",
      "../data/eegmap_split/rest\\train\\uws\\rest_uws_train_0.pt\n",
      "../data/eegmap_split/rest\\train\\uws\\rest_uws_train_0_mcs_uws_label.pt\n",
      "../data/eegmap_split/rest\\test\\uws\\rest_uws_test_0.pt\n",
      "../data/eegmap_split/rest\\test\\uws\\rest_uws_test_0_mcs_uws_label.pt\n",
      "torch.Size([1539, 2400, 10, 11])\n",
      "torch.Size([1539])\n",
      "torch.Size([384, 2400, 10, 11])\n",
      "torch.Size([384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:155: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2696e6abd26746bdb9cb6296d940463d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 0 Training =========\n",
      "tensor([[ 0.1422, -0.1305]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 107.09899950027466\n",
      "Train steps: 1000, Loss: 0.5660539865493774\n",
      "========= Epoch 0 Testing =========\n",
      "Loss: 69.53884887695312 Accuracy: 0.5099999904632568\n",
      "Loss: 138.92340087890625 Accuracy: 0.5299999713897705\n",
      "Loss: 204.9054412841797 Accuracy: 0.5699999928474426\n",
      "Total Loss: 265.3182373046875 Total Accuracy: 0.546875\n",
      "..........Saving the model..........\n",
      "========= Epoch 1 Training =========\n",
      "tensor([[ 0.1584, -0.1132]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 237.78858399391174\n",
      "Train steps: 2000, Loss: 0.566527247428894\n",
      "tensor([[ 0.1193, -0.1291]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 326.9791386127472\n",
      "Train steps: 3000, Loss: 0.576680064201355\n",
      "========= Epoch 1 Testing =========\n",
      "Loss: 67.33521270751953 Accuracy: 0.5899999737739563\n",
      "Loss: 133.53939819335938 Accuracy: 0.6299999952316284\n",
      "Loss: 201.32981872558594 Accuracy: 0.6166666746139526\n",
      "Total Loss: 259.41552734375 Total Accuracy: 0.59375\n",
      "..........Saving the model..........\n",
      "========= Epoch 2 Training =========\n",
      "tensor([[ 0.3029, -0.2297]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 440.426340341568\n",
      "Train steps: 4000, Loss: 0.4618721008300781\n",
      "========= Epoch 2 Testing =========\n",
      "Loss: 64.42540740966797 Accuracy: 0.6299999952316284\n",
      "Loss: 127.6385498046875 Accuracy: 0.6549999713897705\n",
      "Loss: 195.49319458007812 Accuracy: 0.6166666746139526\n",
      "Total Loss: 253.3746337890625 Total Accuracy: 0.59375\n",
      "..........Saving the model..........\n",
      "========= Epoch 3 Training =========\n",
      "tensor([[ 0.2792, -0.2402]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 554.1339704990387\n",
      "Train steps: 5000, Loss: 0.4668028950691223\n",
      "tensor([[-0.4467,  0.6231]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 643.0295453071594\n",
      "Train steps: 6000, Loss: 0.29496675729751587\n",
      "========= Epoch 3 Testing =========\n",
      "Loss: 62.57522201538086 Accuracy: 0.6800000071525574\n",
      "Loss: 129.7349090576172 Accuracy: 0.6499999761581421\n",
      "Loss: 194.52073669433594 Accuracy: 0.643333375453949\n",
      "Total Loss: 246.9011688232422 Total Accuracy: 0.6510416865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 4 Training =========\n",
      "tensor([[ 0.4429, -0.4128]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 757.6196177005768\n",
      "Train steps: 7000, Loss: 0.3541547954082489\n",
      "========= Epoch 4 Testing =========\n",
      "Loss: 62.2733268737793 Accuracy: 0.6299999952316284\n",
      "Loss: 117.43313598632812 Accuracy: 0.6699999570846558\n",
      "Loss: 178.44131469726562 Accuracy: 0.6700000166893005\n",
      "Total Loss: 227.074951171875 Total Accuracy: 0.6666666865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 5 Training =========\n",
      "tensor([[-0.1590,  0.1878]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 869.8938190937042\n",
      "Train steps: 8000, Loss: 0.5347134470939636\n",
      "tensor([[-0.5939,  0.6558]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 958.8865647315979\n",
      "Train steps: 9000, Loss: 0.2520032525062561\n",
      "========= Epoch 5 Testing =========\n",
      "Loss: 57.384334564208984 Accuracy: 0.6699999570846558\n",
      "Loss: 114.6566162109375 Accuracy: 0.6800000071525574\n",
      "Loss: 174.75340270996094 Accuracy: 0.6733333468437195\n",
      "Total Loss: 230.6487274169922 Total Accuracy: 0.6640625\n",
      "..........Saving the model..........\n",
      "========= Epoch 6 Training =========\n",
      "tensor([[-0.6745,  0.8900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1071.5958094596863\n",
      "Train steps: 10000, Loss: 0.18995605409145355\n",
      "========= Epoch 6 Testing =========\n",
      "Loss: 50.27699661254883 Accuracy: 0.7400000095367432\n",
      "Loss: 109.41363525390625 Accuracy: 0.73499995470047\n",
      "Loss: 177.25465393066406 Accuracy: 0.7200000286102295\n",
      "Total Loss: 230.628173828125 Total Accuracy: 0.7135416865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 7 Training =========\n",
      "tensor([[ 2.4075, -2.4328]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1185.486835718155\n",
      "Train steps: 11000, Loss: 0.007873925380408764\n",
      "tensor([[ 1.8619, -1.8802]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1273.9245376586914\n",
      "Train steps: 12000, Loss: 0.023428989574313164\n",
      "========= Epoch 7 Testing =========\n",
      "Loss: 58.7095947265625 Accuracy: 0.7199999690055847\n",
      "Loss: 119.65658569335938 Accuracy: 0.7400000095367432\n",
      "Loss: 168.44810485839844 Accuracy: 0.7300000190734863\n",
      "Total Loss: 217.85731506347656 Total Accuracy: 0.7239583730697632\n",
      "..........Saving the model..........\n",
      "========= Epoch 8 Training =========\n",
      "tensor([[ 3.6724, -3.6345]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1385.5525858402252\n",
      "Train steps: 13000, Loss: 0.0006706849089823663\n",
      "========= Epoch 8 Testing =========\n",
      "Loss: 82.5423812866211 Accuracy: 0.6800000071525574\n",
      "Loss: 150.8531494140625 Accuracy: 0.6949999928474426\n",
      "Loss: 214.31747436523438 Accuracy: 0.6933333277702332\n",
      "Total Loss: 253.50186157226562 Total Accuracy: 0.703125\n",
      "..........Saving the model..........\n",
      "========= Epoch 9 Training =========\n",
      "tensor([[-2.1935,  2.6423]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1497.9726603031158\n",
      "Train steps: 14000, Loss: 0.007909170351922512\n",
      "tensor([[ 1.5789, -1.5215]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1587.3649101257324\n",
      "Train steps: 15000, Loss: 3.1444168090820312\n",
      "========= Epoch 9 Testing =========\n",
      "Loss: 73.04660034179688 Accuracy: 0.6800000071525574\n",
      "Loss: 140.9605712890625 Accuracy: 0.7099999785423279\n",
      "Loss: 203.7720184326172 Accuracy: 0.7133333683013916\n",
      "Total Loss: 259.1038818359375 Total Accuracy: 0.71875\n",
      "..........Saving the model..........\n",
      "========= Epoch 10 Training =========\n",
      "tensor([[ 2.9928, -3.0346]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1699.5403246879578\n",
      "Train steps: 16000, Loss: 0.002408938482403755\n",
      "========= Epoch 10 Testing =========\n",
      "Loss: 82.98375701904297 Accuracy: 0.7099999785423279\n",
      "Loss: 181.25474548339844 Accuracy: 0.675000011920929\n",
      "Loss: 267.93121337890625 Accuracy: 0.6733333468437195\n",
      "Total Loss: 341.4252624511719 Total Accuracy: 0.65625\n",
      "..........Saving the model..........\n",
      "========= Epoch 11 Training =========\n",
      "tensor([[ 2.3542, -2.3067]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1812.3836772441864\n",
      "Train steps: 17000, Loss: 0.009413027204573154\n",
      "tensor([[-3.1714,  3.4968]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1900.893229007721\n",
      "Train steps: 18000, Loss: 0.0012698451755568385\n",
      "========= Epoch 11 Testing =========\n",
      "Loss: 105.81082916259766 Accuracy: 0.75\n",
      "Loss: 196.9591522216797 Accuracy: 0.73499995470047\n",
      "Loss: 258.0676574707031 Accuracy: 0.7400000095367432\n",
      "Total Loss: 339.4836730957031 Total Accuracy: 0.7447916865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 12 Training =========\n",
      "tensor([[ 4.0905, -4.1524]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2013.6814131736755\n",
      "Train steps: 19000, Loss: 0.00026306029758416116\n",
      "tensor([[-2.9564,  3.3555]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2101.491868495941\n",
      "Train steps: 20000, Loss: 0.0018129594391211867\n",
      "========= Epoch 12 Testing =========\n",
      "Loss: 91.69730377197266 Accuracy: 0.6599999666213989\n",
      "Loss: 185.66262817382812 Accuracy: 0.6800000071525574\n",
      "Loss: 263.5240173339844 Accuracy: 0.6899999976158142\n",
      "Total Loss: 313.5041198730469 Total Accuracy: 0.7109375\n",
      "..........Saving the model..........\n",
      "========= Epoch 13 Training =========\n",
      "tensor([[-1.7567,  1.9516]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2213.8936750888824\n",
      "Train steps: 21000, Loss: 0.024222733452916145\n",
      "========= Epoch 13 Testing =========\n",
      "Loss: 95.86526489257812 Accuracy: 0.6399999856948853\n",
      "Loss: 159.07400512695312 Accuracy: 0.7149999737739563\n",
      "Loss: 207.08999633789062 Accuracy: 0.7333333492279053\n",
      "Total Loss: 277.23846435546875 Total Accuracy: 0.734375\n",
      "..........Saving the model..........\n",
      "========= Epoch 14 Training =========\n",
      "tensor([[ 2.3924, -2.3368]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2325.127770423889\n",
      "Train steps: 22000, Loss: 0.008794385939836502\n",
      "tensor([[ 1.9811, -1.8992]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2413.5453724861145\n",
      "Train steps: 23000, Loss: 0.020433049649000168\n",
      "========= Epoch 14 Testing =========\n",
      "Loss: 74.34994506835938 Accuracy: 0.7199999690055847\n",
      "Loss: 135.84701538085938 Accuracy: 0.7249999642372131\n",
      "Loss: 194.58921813964844 Accuracy: 0.7200000286102295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 267.2353210449219 Total Accuracy: 0.7083333730697632\n",
      "..........Saving the model..........\n",
      "========= Epoch 15 Training =========\n",
      "tensor([[-3.1770,  3.5416]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2525.668389558792\n",
      "Train steps: 24000, Loss: 0.001207337831147015\n",
      "========= Epoch 15 Testing =========\n",
      "Loss: 61.4102783203125 Accuracy: 0.7899999618530273\n",
      "Loss: 129.16455078125 Accuracy: 0.7699999809265137\n",
      "Loss: 201.07569885253906 Accuracy: 0.7566666603088379\n",
      "Total Loss: 271.4161071777344 Total Accuracy: 0.75\n",
      "..........Saving the model..........\n",
      "========= Epoch 16 Training =========\n",
      "tensor([[ 3.6778, -3.7873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2638.2439210414886\n",
      "Train steps: 25000, Loss: 0.0005725175142288208\n",
      "tensor([[-2.7193,  2.9506]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2726.7528088092804\n",
      "Train steps: 26000, Loss: 0.0034420788288116455\n",
      "========= Epoch 16 Testing =========\n",
      "Loss: 101.85504913330078 Accuracy: 0.7099999785423279\n",
      "Loss: 172.59039306640625 Accuracy: 0.7450000047683716\n",
      "Loss: 248.39593505859375 Accuracy: 0.7566666603088379\n",
      "Total Loss: 304.8129577636719 Total Accuracy: 0.765625\n",
      "..........Saving the model..........\n",
      "========= Epoch 17 Training =========\n",
      "tensor([[ 4.6595, -4.7202]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2838.0574140548706\n",
      "Train steps: 27000, Loss: 8.439661905867979e-05\n",
      "========= Epoch 17 Testing =========\n",
      "Loss: 86.36214447021484 Accuracy: 0.6499999761581421\n",
      "Loss: 144.71621704101562 Accuracy: 0.7149999737739563\n",
      "Loss: 211.17498779296875 Accuracy: 0.7200000286102295\n",
      "Total Loss: 279.3208312988281 Total Accuracy: 0.71875\n",
      "..........Saving the model..........\n",
      "========= Epoch 18 Training =========\n",
      "tensor([[ 4.4146, -4.5027]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2950.950559616089\n",
      "Train steps: 28000, Loss: 0.00013410145766101778\n",
      "tensor([[ 1.1490, -1.0079]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3038.3932344913483\n",
      "Train steps: 29000, Loss: 0.10946822911500931\n",
      "========= Epoch 18 Testing =========\n",
      "Loss: 55.461631774902344 Accuracy: 0.8199999928474426\n",
      "Loss: 111.27393341064453 Accuracy: 0.8100000023841858\n",
      "Loss: 203.14097595214844 Accuracy: 0.7566666603088379\n",
      "Total Loss: 268.45098876953125 Total Accuracy: 0.7473958730697632\n",
      "..........Saving the model..........\n",
      "========= Epoch 19 Training =========\n",
      "tensor([[-4.3356,  4.7599]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3150.359215259552\n",
      "Train steps: 30000, Loss: 0.00011216964776394889\n",
      "========= Epoch 19 Testing =========\n",
      "Loss: 65.13380432128906 Accuracy: 0.7199999690055847\n",
      "Loss: 127.05091857910156 Accuracy: 0.7699999809265137\n",
      "Loss: 191.68479919433594 Accuracy: 0.7633333802223206\n",
      "Total Loss: 248.9306640625 Total Accuracy: 0.7578125\n",
      "..........Saving the model..........\n",
      "========= Epoch 20 Training =========\n",
      "tensor([[ 3.0632, -3.1349]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3262.3817138671875\n",
      "Train steps: 31000, Loss: 0.00203116936609149\n",
      "tensor([[ 4.2747, -4.1874]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3350.8594999313354\n",
      "Train steps: 32000, Loss: 0.0002113357331836596\n",
      "========= Epoch 20 Testing =========\n",
      "Loss: 61.65013885498047 Accuracy: 0.7699999809265137\n",
      "Loss: 127.35248565673828 Accuracy: 0.7749999761581421\n",
      "Loss: 206.6853485107422 Accuracy: 0.753333330154419\n",
      "Total Loss: 258.2967529296875 Total Accuracy: 0.7604166865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 21 Training =========\n",
      "tensor([[ 4.3650, -4.3372]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3463.581026315689\n",
      "Train steps: 33000, Loss: 0.00016616393986623734\n",
      "========= Epoch 21 Testing =========\n",
      "Loss: 94.61481475830078 Accuracy: 0.7899999618530273\n",
      "Loss: 170.5548095703125 Accuracy: 0.7799999713897705\n",
      "Loss: 247.32470703125 Accuracy: 0.7766667008399963\n",
      "Total Loss: 277.5986328125 Total Accuracy: 0.8020833730697632\n",
      "..........Saving the model..........\n",
      "========= Epoch 22 Training =========\n",
      "tensor([[-3.9806,  4.3578]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3575.341833114624\n",
      "Train steps: 34000, Loss: 0.00023910524032544345\n",
      "tensor([[-4.5176,  4.9276]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3663.8127315044403\n",
      "Train steps: 35000, Loss: 7.903263758635148e-05\n",
      "========= Epoch 22 Testing =========\n",
      "Loss: 44.520137786865234 Accuracy: 0.7699999809265137\n",
      "Loss: 107.9917984008789 Accuracy: 0.75\n",
      "Loss: 160.30545043945312 Accuracy: 0.7599999904632568\n",
      "Total Loss: 201.63636779785156 Total Accuracy: 0.7578125\n",
      "..........Saving the model..........\n",
      "========= Epoch 23 Training =========\n",
      "tensor([[ 1.6243, -1.5240]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3776.5127074718475\n",
      "Train steps: 36000, Loss: 0.04202926903963089\n",
      "========= Epoch 23 Testing =========\n",
      "Loss: 63.24338150024414 Accuracy: 0.8100000023841858\n",
      "Loss: 116.84779357910156 Accuracy: 0.8199999928474426\n",
      "Loss: 178.77923583984375 Accuracy: 0.8066666722297668\n",
      "Total Loss: 246.04766845703125 Total Accuracy: 0.7916666865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 24 Training =========\n",
      "tensor([[-3.0762,  3.3148]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3888.4891471862793\n",
      "Train steps: 37000, Loss: 0.0016751555958762765\n",
      "tensor([[ 4.2202, -4.0894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3977.4436678886414\n",
      "Train steps: 38000, Loss: 0.0002461368858348578\n",
      "========= Epoch 24 Testing =========\n",
      "Loss: 77.30863952636719 Accuracy: 0.7799999713897705\n",
      "Loss: 129.08782958984375 Accuracy: 0.7899999618530273\n",
      "Loss: 190.2514190673828 Accuracy: 0.7933333516120911\n",
      "Total Loss: 247.49090576171875 Total Accuracy: 0.7890625\n",
      "..........Saving the model..........\n",
      "========= Epoch 25 Training =========\n",
      "tensor([[-3.7515,  4.2089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4090.1578226089478\n",
      "Train steps: 39000, Loss: 0.00034898388548754156\n",
      "tensor([[ 2.3957, -2.3042]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4244.837478399277\n",
      "Train steps: 40000, Loss: 0.009054670110344887\n",
      "========= Epoch 25 Testing =========\n",
      "Loss: 63.919193267822266 Accuracy: 0.7899999618530273\n",
      "Loss: 129.01065063476562 Accuracy: 0.7649999856948853\n",
      "Loss: 181.76148986816406 Accuracy: 0.7800000309944153\n",
      "Total Loss: 253.23907470703125 Total Accuracy: 0.7760416865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 26 Training =========\n",
      "tensor([[-3.4818,  3.8352]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4450.622779607773\n",
      "Train steps: 41000, Loss: 0.000663894519675523\n",
      "========= Epoch 26 Testing =========\n",
      "Loss: 84.31574249267578 Accuracy: 0.7799999713897705\n",
      "Loss: 186.63629150390625 Accuracy: 0.73499995470047\n",
      "Loss: 292.7839050292969 Accuracy: 0.75\n",
      "Total Loss: 360.5289001464844 Total Accuracy: 0.7630208730697632\n",
      "..........Saving the model..........\n",
      "========= Epoch 27 Training =========\n",
      "tensor([[-4.3604,  4.7705]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4652.429089784622\n",
      "Train steps: 42000, Loss: 0.00010823617776622996\n",
      "tensor([[ 4.2946, -4.2014]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 4810.384864330292\n",
      "Train steps: 43000, Loss: 0.00020430385484360158\n",
      "========= Epoch 27 Testing =========\n",
      "Loss: 74.05168914794922 Accuracy: 0.7699999809265137\n",
      "Loss: 148.52345275878906 Accuracy: 0.7599999904632568\n",
      "Loss: 227.201171875 Accuracy: 0.7700000405311584\n",
      "Total Loss: 284.19610595703125 Total Accuracy: 0.7682291865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 28 Training =========\n",
      "tensor([[-2.9118,  3.1509]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 5011.964025735855\n",
      "Train steps: 44000, Loss: 0.0023254514671862125\n",
      "========= Epoch 28 Testing =========\n",
      "Loss: 71.8367919921875 Accuracy: 0.7899999618530273\n",
      "Loss: 144.64051818847656 Accuracy: 0.7799999713897705\n",
      "Loss: 222.04281616210938 Accuracy: 0.7800000309944153\n",
      "Total Loss: 305.5123596191406 Total Accuracy: 0.7682291865348816\n",
      "..........Saving the model..........\n",
      "========= Epoch 29 Training =========\n",
      "tensor([[-4.3009,  4.7858]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 5217.396449804306\n",
      "Train steps: 45000, Loss: 0.00011312322021694854\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(dataset,mode):\n",
    "    # find the fold file\n",
    "    count = 0\n",
    "    for person in range(len(dataset)):\n",
    "        filename = os.path.join(dataset.path, dataset.file_path[person])\n",
    "        # extract the pure name of the file\n",
    "        parts = filename.split(\"\\\\\")\n",
    "        file_name = parts[-1]\n",
    "        name_without_extension = file_name.split(\".\")[0]\n",
    "        # label or data\n",
    "        file_last = name_without_extension.split(\"_\")[-1]\n",
    "        if file_last.isdigit(): # data\n",
    "            # is this fold or not\n",
    "            if int(file_last) == fold: # yes\n",
    "                print(filename)\n",
    "                count = count + 1\n",
    "                data_map = torch.load(filename)\n",
    "                # train or test\n",
    "                if name_without_extension.split(\"_\")[-2] == \"train\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        train_data.append(data_map[i])\n",
    "                elif name_without_extension.split(\"_\")[-2] == \"test\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        test_data.append(data_map[i])\n",
    "                if count == 4:\n",
    "                    del data_map\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache() \n",
    "                    break\n",
    "            else:   # not\n",
    "                pass\n",
    "        else: # label\n",
    "            file_last = name_without_extension.split(\"_\")[-4]\n",
    "            file_mode = name_without_extension.split(\"_\")[-2]\n",
    "            if file_mode == mode.split(\"_\")[-1]: # is this mode or not\n",
    "                # is this fold or not\n",
    "                if int(file_last) == fold: # yes\n",
    "                    print(filename)\n",
    "                    count = count + 1\n",
    "                    data_map = torch.load(filename)\n",
    "                    # train or test\n",
    "                    if name_without_extension.split(\"_\")[-5] == \"train\":\n",
    "                        for i in range(data_map.size(0)):\n",
    "                            train_label.append(data_map[i])\n",
    "                    elif name_without_extension.split(\"_\")[-5] == \"test\":\n",
    "                        for i in range(data_map.size(0)):\n",
    "                            test_label.append(data_map[i])\n",
    "                    if count == 4:\n",
    "                        del data_map\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache() \n",
    "                        break\n",
    "                else:   # not\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        del filename, parts, file_name, name_without_extension, file_last\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()    \n",
    "# 定义LSTM超参数\n",
    "input_size = 64  # 输入特征维度\n",
    "hidden_size = 64  # 隐藏单元数量\n",
    "num_layers = 2  # LSTM层数\n",
    "output_size = 2  # 输出类别数量\n",
    "# 创建模型实例\n",
    "# model_list = ['', '_CNN', '_CNN_spa', '_CNN_spa_lstm']\n",
    "# model_name = model_list[0]\n",
    "# if model_name == model_list[0]: #  CascadeCept\n",
    "#     from network_cnn_lstm import MyNetwork\n",
    "# elif model_name == model_list[1]: #  CNN\n",
    "#     from network_cnn_lstm_2 import MyNetwork\n",
    "# elif model_name == model_list[2]: # CascadeCept_1\n",
    "#     from network_cnn_lstm_3 import MyNetwork\n",
    "# elif model_name == model_list[3]: # CascadeCept_2\n",
    "#     from network_cnn_lstm_4 import MyNetwork\n",
    "model_list = ['_1', '_2', '_3', '_4']\n",
    "model_name = model_list[1]\n",
    "if model_name == model_list[0]: #  CascadeCept\n",
    "    from net_cnn_lstm1 import MyNetwork\n",
    "elif model_name == model_list[1]: #  CascadeCept:\n",
    "    from net_cnn_lstm2 import MyNetwork\n",
    "model = MyNetwork(input_size, hidden_size, num_layers, output_size)\n",
    "model = model.to(device)\n",
    "\n",
    "# experimental dir: rest, conditionA, conditionB, conditionC\n",
    "exper_dir = \"rest\"\n",
    "root_dir = f\"../data/eegmap_split/{exper_dir}\"\n",
    "# classification = \"hc_doc\"/doc or \"mcs_uws\"/uws\n",
    "classification = \"mcs_uws\"\n",
    "# classification = \"mcs_uws\"\n",
    "fold_num = 5\n",
    "for fold in tqdm(range(5)):\n",
    "    # train num folds\n",
    "#     fold = 0 # 选择折数\n",
    "    # -- prepare datasets\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    \n",
    "    if classification == \"hc_doc\":\n",
    "        # ---- hc\n",
    "        dataset = MyData(root_dir, \"train\", \"hc\") # hc\n",
    "        make_dataset(dataset,classification)\n",
    "        dataset = MyData(root_dir, \"test\", \"hc\") # hc\n",
    "        make_dataset(dataset,classification)\n",
    "    # ---- mcs\n",
    "    dataset = MyData(root_dir, \"train\", \"mcs\") # mcs\n",
    "    make_dataset(dataset,classification)\n",
    "    dataset = MyData(root_dir, \"test\", \"mcs\") # hc\n",
    "    make_dataset(dataset,classification)\n",
    "    # ---- uws\n",
    "    dataset = MyData(root_dir, \"train\", \"uws\") # uws\n",
    "    make_dataset(dataset,classification)\n",
    "    dataset = MyData(root_dir, \"test\", \"uws\") # hc\n",
    "    make_dataset(dataset,classification)\n",
    "    \n",
    "    print(torch.stack(train_data).size())\n",
    "    print(torch.stack(train_label).size())\n",
    "    print(torch.stack(test_data).size())\n",
    "    print(torch.stack(test_label).size())\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "    \n",
    "    train_data = torch.stack(train_data)\n",
    "    train_label = torch.stack(train_label)\n",
    "    test_data = torch.stack(test_data)\n",
    "    test_label = torch.stack(test_label)\n",
    "    # train dataset\n",
    "    train_td = TensorDataset(train_data, train_label)\n",
    "    train_loader = DataLoader(train_td, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    # test dataset\n",
    "    test_td = TensorDataset(test_data, test_label)\n",
    "    test_loader = DataLoader(test_td, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    del train_data, train_label, test_data, test_label, train_td, test_td\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # set model for each fold\n",
    "    model = MyNetwork(input_size, hidden_size, num_layers, output_size)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learn_rate)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 30, 50], gamma=0.2)\n",
    "    # -- start training\n",
    "    start_time = time.time()\n",
    "    # train and test step records\n",
    "    total_train_step = 0\n",
    "    total_test_step = 0\n",
    "    min_test_loss = 1000\n",
    "    # add Tensorboard\n",
    "    writer_train = SummaryWriter(f\"../logs/{classification}/{exper_dir}{model_name}/logs_train_{fold}\")\n",
    "    writer_valid = SummaryWriter(f\"../logs/{classification}/{exper_dir}{model_name}/logs_test_{fold}\")\n",
    "    writer_valid_acc = SummaryWriter(f\"../logs/{classification}/{exper_dir}{model_name}/logs_test_acc_{fold}\")\n",
    "    for i in tqdm(range(num_epochs)):  \n",
    "        print(f\"========= Epoch {i} Training =========\")\n",
    "        # train steps\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            # x, y\n",
    "            data_map, label=data\n",
    "            data_map_reshaped = torch.reshape(data_map, (110, 1, 1, 2400))\n",
    "            label_int = label.long()\n",
    "            data_map_reshaped=data_map_reshaped.to(device)\n",
    "            label_int=label_int.to(device)\n",
    "            del data_map, label\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # y_pred\n",
    "            label_pred = model(data_map_reshaped)\n",
    "            # Loss Computation and Optimization\n",
    "            loss = criterion(label_pred,label_int)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # draw tensorboard\n",
    "            total_train_step = total_train_step + 1\n",
    "            # print info\n",
    "            if total_train_step % 1000 == 0:\n",
    "                end_time = time.time()\n",
    "                print(label_pred)\n",
    "                print(f\"Train time: {end_time - start_time}\")\n",
    "                print(f\"Train steps: {total_train_step}, Loss: {loss.item()}\")\n",
    "            writer_train.add_scalar(\"train_loss\",loss.item(),total_train_step)\n",
    "            # Clear gpu\n",
    "            del data, data_map_reshaped, label_int, label_pred, loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Evaluation and save the best model\n",
    "        print(f\"========= Epoch {i} Testing =========\")\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        test_count = 0\n",
    "        total_test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                test_count = test_count + 1\n",
    "                # x, y\n",
    "                data_map, label=data\n",
    "                data_map_reshaped = torch.reshape(data_map, (110, 1, 1, 2400))\n",
    "                label_int = label.long()\n",
    "                data_map_reshaped = data_map_reshaped.to(device)\n",
    "                label_int = label_int.to(device)\n",
    "                del data_map, label\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                # y_pred\n",
    "                label_pred_test = model(data_map_reshaped)\n",
    "                loss = criterion(label_pred_test,label_int)\n",
    "#                 print(label_pred_test)\n",
    "                # accuracy \n",
    "                total_test_acc = total_test_acc + ((label_pred_test.argmax(1)) == label_int).sum()\n",
    "                # draw tensorboad\n",
    "                total_test_loss = total_test_loss + loss\n",
    "                if test_count % 100 == 0:\n",
    "                    print(f\"Loss: {total_test_loss} Accuracy: {total_test_acc/test_count}\")\n",
    "                # Clear gpu\n",
    "                del data_map_reshaped, label_int, label_pred_test, loss, data\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "        print(f\"Total Loss: {total_test_loss} Total Accuracy: {total_test_acc/test_count}\")\n",
    "        writer_valid.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "        writer_valid_acc.add_scalar(\"test_acc\", total_test_acc/test_count, total_test_step)\n",
    "        total_test_step = total_test_step + 1\n",
    "        print(\"..........Saving the model..........\")\n",
    "        torch.save(model.state_dict(),f\"../models/{classification}/{exper_dir}{model_name}/Fold{fold}_Epoch{i}.pt\") \n",
    "#         if total_test_loss < min_test_loss:\n",
    "#             min_test_loss = total_test_loss\n",
    "#             print(\"..........Saving the model..........\")\n",
    "#             torch.save(model.state_dict(),f\"../model/{exper_dir}/Fold{fold}_Epoch{i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099a8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
