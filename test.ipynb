{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43442f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from load_data import MyData  # self-made\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm_notebook as tqdm # View procedure\n",
    "import os\n",
    "import scipy.io\n",
    "from random import random\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from network_cnn_lstm import MyNetwork\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4beff",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de949af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_map size: torch.Size([123, 2400, 10, 11])\n",
      "data_map size: torch.Size([123])\n",
      "data_map size: torch.Size([135, 2400, 10, 11])\n",
      "data_map size: torch.Size([135])\n",
      "data_map size: torch.Size([122, 2400, 10, 11])\n",
      "data_map size: torch.Size([122])\n",
      "torch.Size([380, 2400, 10, 11])\n",
      "torch.Size([380])\n"
     ]
    }
   ],
   "source": [
    "# exper_dir = \"rest\"\n",
    "exper_dir = \"conditionC\"\n",
    "root_dir = f\"../data/eegmap_split/{exper_dir}\"\n",
    "test_data = []\n",
    "test_label = []\n",
    "# ---- hc\n",
    "dataset = MyData(root_dir, f\"test\", \"hc\") # hc\n",
    "# find the fold file\n",
    "for person in range(len(dataset)):\n",
    "    filename = os.path.join(dataset.path, dataset.file_path[person])\n",
    "    data_map = torch.load(filename)\n",
    "    print(f\"data_map size: {data_map.size()}\")\n",
    "    # extract the pure name of the file\n",
    "    parts = filename.split(\"\\\\\")\n",
    "    file_name = parts[-1]\n",
    "    name_without_extension = file_name.split(\".\")[0]\n",
    "    # label or data\n",
    "    file_last = name_without_extension.split(\"_\")[-1]\n",
    "    if file_last == \"label\": # label\n",
    "        for label in data_map:\n",
    "            test_label.append(label)\n",
    "    else: # data\n",
    "        for data in data_map:\n",
    "            test_data.append(data)\n",
    "    del filename, parts, name_without_extension, file_last\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()   \n",
    "# ---- mcs\n",
    "dataset = MyData(root_dir, \"test\", \"mcs\") \n",
    "# find the fold file\n",
    "for person in range(len(dataset)):\n",
    "    filename = os.path.join(dataset.path, dataset.file_path[person])\n",
    "    data_map = torch.load(filename)\n",
    "    print(f\"data_map size: {data_map.size()}\")\n",
    "    # extract the pure name of the file\n",
    "    parts = filename.split(\"\\\\\")\n",
    "    file_name = parts[-1]\n",
    "    name_without_extension = file_name.split(\".\")[0]\n",
    "    # label or data\n",
    "    file_last = name_without_extension.split(\"_\")[-1]\n",
    "    if file_last == \"label\": # label\n",
    "        for label in data_map:\n",
    "            test_label.append(label)\n",
    "    else: # data\n",
    "        for data in data_map:\n",
    "            test_data.append(data)\n",
    "    del filename, parts, name_without_extension, file_last\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "# ---- uws\n",
    "dataset = MyData(root_dir, \"test\", \"uws\") # uws\n",
    "# find the fold file\n",
    "for person in range(len(dataset)):\n",
    "    filename = os.path.join(dataset.path, dataset.file_path[person])\n",
    "    data_map = torch.load(filename)\n",
    "    print(f\"data_map size: {data_map.size()}\")\n",
    "    # extract the pure name of the file\n",
    "    parts = filename.split(\"\\\\\")\n",
    "    file_name = parts[-1]\n",
    "    name_without_extension = file_name.split(\".\")[0]\n",
    "    # label or data\n",
    "    file_last = name_without_extension.split(\"_\")[-1]\n",
    "    if file_last == \"label\": # label\n",
    "        for label in data_map:\n",
    "            test_label.append(label)\n",
    "    else: # data\n",
    "        for data in data_map:\n",
    "            test_data.append(data)\n",
    "    del filename, parts, name_without_extension, file_last\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "test_data = torch.stack(test_data)\n",
    "test_label = torch.stack(test_label)\n",
    "print(test_data.size())\n",
    "print(test_label.size())\n",
    "test_data_size = test_label.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb412c1",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3990ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "C,H,W = 1,1,2400\n",
    "learn_rate = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21c6316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# test dataset\n",
    "test_td = TensorDataset(test_data, test_label)\n",
    "test_loader = DataLoader(test_td, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b84bf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data\n",
    "del test_label\n",
    "del test_td\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2320189",
   "metadata": {},
   "source": [
    "# Ensuring deterministicity through Random seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3fc41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "manualSeed = 4\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aca157",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42d26754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:46: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80db1a790e614c75b9e6d04441c80aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 == Loss:188.28136830031872 == Accuracy:0.7210526466369629\n",
      "Epoch 1 == Loss:195.97980684041977 == Accuracy:0.7315790057182312\n",
      "Epoch 2 == Loss:203.0951280593872 == Accuracy:0.7421053051948547\n",
      "Epoch 3 == Loss:154.68102085217834 == Accuracy:0.8421052694320679\n",
      "Epoch 4 == Loss:57.240309327840805 == Accuracy:0.9315789937973022\n",
      "Epoch 5 == Loss:97.1796238356037 == Accuracy:0.9078947901725769\n",
      "Epoch 6 == Loss:104.13697498428519 == Accuracy:0.9078947901725769\n",
      "Epoch 7 == Loss:91.41538896714337 == Accuracy:0.936842143535614\n",
      "Epoch 8 == Loss:54.048823503544554 == Accuracy:0.9473684430122375\n",
      "Epoch 9 == Loss:60.20170302016777 == Accuracy:0.9210526943206787\n",
      "Epoch 10 == Loss:31.488259225261572 == Accuracy:0.9710526466369629\n",
      "Epoch 11 == Loss:47.326225097931456 == Accuracy:0.9605263471603394\n",
      "Epoch 12 == Loss:19.119243070381344 == Accuracy:0.9842105507850647\n",
      "Epoch 13 == Loss:48.424981949116045 == Accuracy:0.9684211015701294\n",
      "Epoch 14 == Loss:61.528444454289456 == Accuracy:0.9657894968986511\n",
      "Epoch 15 == Loss:51.79637892019571 == Accuracy:0.9763158559799194\n",
      "Epoch 16 == Loss:58.29598332780503 == Accuracy:0.9763158559799194\n",
      "Epoch 17 == Loss:94.15469814818834 == Accuracy:0.9657894968986511\n",
      "Epoch 18 == Loss:72.10721806679528 == Accuracy:0.9763158559799194\n",
      "Epoch 19 == Loss:160.59650140796847 == Accuracy:0.9500000476837158\n",
      "Epoch 20 == Loss:123.34343954439852 == Accuracy:0.9657894968986511\n",
      "Epoch 21 == Loss:127.04058624423112 == Accuracy:0.9657894968986511\n",
      "Epoch 22 == Loss:179.1945832241057 == Accuracy:0.9605263471603394\n",
      "Epoch 23 == Loss:65.93268394116387 == Accuracy:0.9815790057182312\n",
      "Epoch 24 == Loss:176.878232224566 == Accuracy:0.9657894968986511\n",
      "Epoch 25 == Loss:139.01912805608674 == Accuracy:0.9657894968986511\n",
      "Epoch 26 == Loss:190.79402501898642 == Accuracy:0.9500000476837158\n",
      "Epoch 27 == Loss:147.0938508418887 == Accuracy:0.9657894968986511\n",
      "Epoch 28 == Loss:167.30219753813424 == Accuracy:0.9657894968986511\n",
      "Epoch 29 == Loss:189.43172046219053 == Accuracy:0.9631579518318176\n",
      "Epoch 30 == Loss:271.3670984721671 == Accuracy:0.9421052932739258\n",
      "Epoch 31 == Loss:166.01281302018964 == Accuracy:0.9631579518318176\n",
      "Epoch 32 == Loss:178.39089561422696 == Accuracy:0.9657894968986511\n",
      "Epoch 33 == Loss:222.34414413720924 == Accuracy:0.9526315927505493\n",
      "Epoch 34 == Loss:206.4503471074617 == Accuracy:0.9552631974220276\n",
      "Epoch 35 == Loss:169.08843897568175 == Accuracy:0.9710526466369629\n",
      "Epoch 36 == Loss:152.3033349176929 == Accuracy:0.9684211015701294\n",
      "Epoch 37 == Loss:126.32795846784384 == Accuracy:0.9763158559799194\n",
      "Epoch 38 == Loss:169.43113460893267 == Accuracy:0.9657894968986511\n",
      "Epoch 39 == Loss:181.83669853053726 == Accuracy:0.9657894968986511\n",
      "Epoch 40 == Loss:150.88702001048966 == Accuracy:0.9657894968986511\n",
      "Epoch 41 == Loss:131.17860619870896 == Accuracy:0.9710526466369629\n",
      "Epoch 42 == Loss:186.75797658902457 == Accuracy:0.9605263471603394\n",
      "Epoch 43 == Loss:175.4565262656405 == Accuracy:0.9657894968986511\n",
      "Epoch 44 == Loss:160.52106046839373 == Accuracy:0.9657894968986511\n",
      "Epoch 45 == Loss:262.80392903173185 == Accuracy:0.9421052932739258\n",
      "Epoch 46 == Loss:183.66721213579547 == Accuracy:0.9605263471603394\n",
      "Epoch 47 == Loss:170.8633569333245 == Accuracy:0.9684211015701294\n",
      "Epoch 48 == Loss:161.07997070711625 == Accuracy:0.9684211015701294\n",
      "Epoch 49 == Loss:187.09503690102014 == Accuracy:0.9631579518318176\n",
      "Epoch 50 == Loss:166.59199920751277 == Accuracy:0.9657894968986511\n",
      "Epoch 51 == Loss:159.80762397703722 == Accuracy:0.9631579518318176\n",
      "Epoch 52 == Loss:209.1861234194575 == Accuracy:0.9605263471603394\n",
      "Epoch 53 == Loss:172.84757826456004 == Accuracy:0.9684211015701294\n",
      "Epoch 54 == Loss:196.00375320803656 == Accuracy:0.9631579518318176\n",
      "Epoch 55 == Loss:142.71344100288076 == Accuracy:0.9710526466369629\n",
      "Epoch 56 == Loss:272.9040845889888 == Accuracy:0.936842143535614\n",
      "Epoch 57 == Loss:176.44792393453332 == Accuracy:0.9710526466369629\n",
      "Epoch 58 == Loss:110.49221063104577 == Accuracy:0.9763158559799194\n",
      "Epoch 59 == Loss:266.91797092936906 == Accuracy:0.936842143535614\n",
      "Epoch 60 == Loss:227.53074699547443 == Accuracy:0.9473684430122375\n",
      "Epoch 61 == Loss:182.85136326261613 == Accuracy:0.9657894968986511\n",
      "Epoch 62 == Loss:190.5541698222852 == Accuracy:0.9657894968986511\n",
      "Epoch 63 == Loss:239.34952508063967 == Accuracy:0.9526315927505493\n",
      "Epoch 64 == Loss:146.48765088869416 == Accuracy:0.9684211015701294\n",
      "Epoch 65 == Loss:194.7017002974408 == Accuracy:0.9578948020935059\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda:0\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# 加载预训练模型!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# 定义LSTM超参数\n",
    "input_size = 64  # 输入特征维度\n",
    "hidden_size = 64  # 隐藏单元数量\n",
    "num_layers = 2  # LSTM层数\n",
    "output_size = 2  # 输出类别数量\n",
    "\n",
    "# ==损失函数权重\n",
    "# ======== 二分类-HC/DOC\n",
    "# 计算总样本数量\n",
    "# condition1\n",
    "# total_samples = 887 + 985 + 879\n",
    "# condition2\n",
    "# total_samples = 929 + 1029 + 886\n",
    "# condition3\n",
    "total_samples = 887 + 975 + 879\n",
    "# 计算每个类别的权重\n",
    "# condition1\n",
    "# weights = [total_samples / 887, total_samples / (985 + 879)]\n",
    "# condition2\n",
    "# weights = [total_samples / 929, total_samples / (1029 + 886)]\n",
    "# condition3\n",
    "weights = [total_samples / 887, total_samples / (975 + 879)]\n",
    "# # ======== 三分类\n",
    "# # 计算总样本数量\n",
    "# # conditionB\n",
    "# total_samples = 929 + 1029 + 886\n",
    "# # 计算每个类别的权重\n",
    "# # conditionB\n",
    "# weights = [total_samples / 929, total_samples / 1029, total_samples / 886]\n",
    "\n",
    "# 将权重转换为张量\n",
    "weights_tensor = torch.tensor(weights, device=device)\n",
    "\n",
    "# 定义交叉熵损失函数并设置权重\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "fold = 4\n",
    "begin = 0\n",
    "end = 66\n",
    "for i in tqdm(range(begin,end)):\n",
    "    model = MyNetwork(input_size, hidden_size, num_layers, output_size)\n",
    "    model.load_state_dict(torch.load(f\"../model/hc_doc/{exper_dir}/Fold{fold}_Epoch{i}.pt\"))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    model.eval()\n",
    "    # 初始化损失和准确率\n",
    "    total_test_loss = 0\n",
    "    total_acc_hc = 0\n",
    "    total_acc_mcs = 0\n",
    "    total_acc_uws = 0\n",
    "    total_accuracy = 0\n",
    "    # 计数\n",
    "    test_count = 0\n",
    "    hc_count = 0\n",
    "    mcs_count = 0\n",
    "    uws_count = 0\n",
    "    # 用于绘制混淆矩阵\n",
    "    predict_labels = torch.tensor([])\n",
    "    predict_labels = predict_labels.to(device)\n",
    "    true_labels = torch.tensor([])\n",
    "    true_labels = true_labels.to(device)\n",
    "    with torch.no_grad(): # 设置不进行后向传播\n",
    "        for data in test_loader:\n",
    "            test_count = test_count + 1\n",
    "            data_map, label=data # x,y\n",
    "            # x\n",
    "            data_map_reshaped = torch.reshape(data_map, (110, 1, 1, 2400))\n",
    "            data_map_reshaped = data_map_reshaped.to(device)\n",
    "            # y\n",
    "            label_int = label.long()\n",
    "            label_int = label_int.to(device)\n",
    "            # clear gpu\n",
    "            del data_map\n",
    "            del label\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # y_pred\n",
    "            label_pred_test = model(data_map_reshaped)\n",
    "\n",
    "            # confusion matrix\n",
    "            predict_labels = torch.cat((predict_labels, label_pred_test.argmax(1)), dim=0)\n",
    "            true_labels = torch.cat((true_labels, label_int), dim=0)\n",
    "    #         print(predict_labels)\n",
    "    #         print(true_labels)\n",
    "    #         predict_labels = torch.tensor([predict_labels,label_pred_test.argmax(1)[0]])\n",
    "    #         true_labels = torch.tensor([true_labels,label_int])\n",
    "\n",
    "            # loss\n",
    "            loss = criterion(label_pred_test,label_int)\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            accuracy = ((label_pred_test.argmax(1)) == label_int).sum()\n",
    "            if label_int == 0:\n",
    "                total_acc_hc = total_acc_hc + accuracy\n",
    "                hc_count = hc_count + 1\n",
    "            elif label_int == 1:\n",
    "                total_acc_mcs = total_acc_mcs + accuracy\n",
    "                mcs_count = mcs_count + 1\n",
    "            elif label_int == 2:\n",
    "                total_acc_uws = total_acc_uws + accuracy\n",
    "                uws_count = uws_count + 1\n",
    "#             if test_count % 100 == 0:\n",
    "#                 print(f\"共{test_count}组，准确{total_acc_hc+total_acc_mcs+total_acc_uws}个\")\n",
    "#                 print(f\"    HC:{total_acc_hc}个, MCS:{total_acc_mcs}个，UWS:{total_acc_uws}个\")\n",
    "#                 print(f\"准确率:{(total_acc_hc+total_acc_mcs+total_acc_uws) / test_count}\")\n",
    "#                 print(f\"    HC:{total_acc_hc/hc_count}, MCS:{total_acc_mcs/mcs_count}，UWS:{total_acc_uws/uws_count}\")\n",
    "#     print(f\"共{test_count}组，准确{total_acc_hc+total_acc_mcs+total_acc_uws}个\")\n",
    "#     print(f\"    HC:{total_acc_hc}个, MCS:{total_acc_mcs}个，UWS:{total_acc_uws}个\")\n",
    "    print(f\"Epoch {i} == Loss:{total_test_loss} == Accuracy:{(total_acc_hc+total_acc_mcs+total_acc_uws) / test_count}\")\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "#     print(f\"整体测试集上的Loss: {total_test_loss}\")\n",
    "#     print(f\"整体测试集上的准确率: {(total_acc_hc+total_acc_mcs+total_acc_uws) / test_count}\")\n",
    "#     print(f\"hc准确率: {total_acc_hc / hc_count}\")\n",
    "#     print(f\"mcs准确率: {total_acc_mcs / mcs_count}\")\n",
    "#     print(f\"uws准确率: {total_acc_uws / uws_count}\")\n",
    "    # writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    # writer.add_scalar(\"test_accuracy\", total_accuracy / test_data_size, total_test_step)\n",
    "    # total_test_step = total_test_step + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6540c9",
   "metadata": {},
   "source": [
    "# Single Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "907aeb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共20组，准确18个\n",
      "    HC:6个, MCS:6个，UWS:6个\n",
      "准确率:0.9000000357627869\n",
      "    HC:1.0, MCS:1.0，UWS:0.75\n",
      "共40组，准确37个\n",
      "    HC:10个, MCS:15个，UWS:12个\n",
      "准确率:0.925000011920929\n",
      "    HC:1.0, MCS:1.0，UWS:0.8000000715255737\n",
      "共60组，准确56个\n",
      "    HC:17个, MCS:24个，UWS:15个\n",
      "准确率:0.9333333969116211\n",
      "    HC:0.944444477558136, MCS:1.0，UWS:0.8333333134651184\n",
      "共80组，准确74个\n",
      "    HC:28个, MCS:29个，UWS:17个\n",
      "准确率:0.925000011920929\n",
      "    HC:0.9655172228813171, MCS:1.0，UWS:0.7727273106575012\n",
      "共100组，准确94个\n",
      "    HC:33个, MCS:39个，UWS:22个\n",
      "准确率:0.9399999976158142\n",
      "    HC:0.9705882668495178, MCS:1.0，UWS:0.8148148059844971\n",
      "共120组，准确114个\n",
      "    HC:39个, MCS:46个，UWS:29个\n",
      "准确率:0.9500000476837158\n",
      "    HC:0.9750000238418579, MCS:1.0，UWS:0.8529411554336548\n",
      "共140组，准确134个\n",
      "    HC:47个, MCS:54个，UWS:33个\n",
      "准确率:0.9571428894996643\n",
      "    HC:0.9791666865348816, MCS:1.0，UWS:0.8684210777282715\n",
      "共160组，准确153个\n",
      "    HC:54个, MCS:61个，UWS:38个\n",
      "准确率:0.956250011920929\n",
      "    HC:0.9818181395530701, MCS:0.9999999403953552，UWS:0.8636363744735718\n",
      "共180组，准确173个\n",
      "    HC:57个, MCS:73个，UWS:43个\n",
      "准确率:0.9611111283302307\n",
      "    HC:0.982758641242981, MCS:1.0，UWS:0.8775510191917419\n",
      "共200组，准确193个\n",
      "    HC:62个, MCS:82个，UWS:49个\n",
      "准确率:0.9649999737739563\n",
      "    HC:0.9841270446777344, MCS:0.9999999403953552，UWS:0.8909090757369995\n",
      "共220组，准确211个\n",
      "    HC:68个, MCS:88个，UWS:55个\n",
      "准确率:0.9590908885002136\n",
      "    HC:0.9855072498321533, MCS:0.9887640476226807，UWS:0.8870967626571655\n",
      "共240组，准确229个\n",
      "    HC:79个, MCS:90个，UWS:60个\n",
      "准确率:0.9541667103767395\n",
      "    HC:0.987500011920929, MCS:0.9890109896659851，UWS:0.8695652484893799\n",
      "共260组，准确249个\n",
      "    HC:82个, MCS:98个，UWS:69个\n",
      "准确率:0.9576923251152039\n",
      "    HC:0.9879517555236816, MCS:0.9898989796638489，UWS:0.884615421295166\n",
      "共280组，准确269个\n",
      "    HC:90个, MCS:101个，UWS:78个\n",
      "准确率:0.9607142806053162\n",
      "    HC:0.9890109896659851, MCS:0.9901961088180542，UWS:0.8965517282485962\n",
      "共300组，准确289个\n",
      "    HC:98个, MCS:110个，UWS:81个\n",
      "准确率:0.9633333683013916\n",
      "    HC:0.9898989796638489, MCS:0.9909909963607788，UWS:0.9000000357627869\n",
      "共320组，准确308个\n",
      "    HC:102个, MCS:113个，UWS:93个\n",
      "准确率:0.9625000357627869\n",
      "    HC:0.9902912974357605, MCS:0.9826086759567261，UWS:0.9117647409439087\n",
      "共340组，准确328个\n",
      "    HC:109个, MCS:121个，UWS:98个\n",
      "准确率:0.9647058844566345\n",
      "    HC:0.9909090399742126, MCS:0.9837397933006287，UWS:0.9158878326416016\n",
      "共360组，准确348个\n",
      "    HC:115个, MCS:126个，UWS:107个\n",
      "准确率:0.9666666984558105\n",
      "    HC:0.9913793206214905, MCS:0.984375，UWS:0.9224137663841248\n",
      "共380组，准确366个\n",
      "    HC:122个, MCS:134个，UWS:110个\n",
      "准确率:0.9631579518318176\n",
      "    HC:0.9918698668479919, MCS:0.9852941036224365，UWS:0.9090908765792847\n",
      "共380组，准确366个\n",
      "    HC:122个, MCS:134个，UWS:110个\n",
      "整体测试集上的Loss: 65.3148784040277\n",
      "整体测试集上的准确率: 0.9631579518318176\n",
      "hc准确率: 0.9918698668479919\n",
      "mcs准确率: 0.9852941036224365\n",
      "uws准确率: 0.9090908765792847\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda:0\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 加载预训练模型!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# 定义LSTM超参数\n",
    "input_size = 64  # 输入特征维度\n",
    "hidden_size = 64  # 隐藏单元数量\n",
    "num_layers = 2  # LSTM层数\n",
    "output_size = 3  # 输出类别数量\n",
    "model = MyNetwork(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# ConditionA\n",
    "model.load_state_dict(torch.load(f\"../model/{exper_dir}/Fold2_Epoch20.pt\")) \n",
    "# ConditionB\n",
    "# model.load_state_dict(torch.load(f\"../model/{exper_dir}/Fold3_Epoch19.pt\")) \n",
    "model = model.to(device)\n",
    "\n",
    "# # 计算总样本数量\n",
    "# # conditionB\n",
    "total_samples = 929 + 1029 + 886\n",
    "# # conditionC\n",
    "# total_samples = 1108 + 1218 + 1098\n",
    "\n",
    "# # 计算每个类别的权重\n",
    "# # conditionB\n",
    "weights = [total_samples / 929, total_samples / 1029, total_samples / 886]\n",
    "# # conditionC\n",
    "# weights = [total_samples / 1108, total_samples / 1218, total_samples / 1098]\n",
    "\n",
    "# # 将权重转换为张量\n",
    "weights_tensor = torch.tensor(weights, device=device)\n",
    "\n",
    "# # 定义交叉熵损失函数并设置权重\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.SmoothL1Loss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "# 测试步骤开始\n",
    "model.eval()\n",
    "# 初始化损失和准确率\n",
    "total_test_loss = 0\n",
    "total_acc_hc = 0\n",
    "total_acc_mcs = 0\n",
    "total_acc_uws = 0\n",
    "total_accuracy = 0\n",
    "# 计数\n",
    "test_count = 0\n",
    "hc_count = 0\n",
    "mcs_count = 0\n",
    "uws_count = 0\n",
    "# 用于绘制混淆矩阵\n",
    "predict_labels = torch.tensor([])\n",
    "predict_labels = predict_labels.to(device)\n",
    "true_labels = torch.tensor([])\n",
    "true_labels = true_labels.to(device)\n",
    "with torch.no_grad(): # 设置不进行后向传播\n",
    "    for data in test_loader:\n",
    "        test_count = test_count + 1\n",
    "        data_map, label=data # x,y\n",
    "        # x\n",
    "        data_map_reshaped = torch.reshape(data_map, (110, 1, 1, 2400))\n",
    "        data_map_reshaped = data_map_reshaped.to(device)\n",
    "        # y\n",
    "        label_int = label.long()\n",
    "        label_int = label_int.to(device)\n",
    "        # clear gpu\n",
    "        del data_map\n",
    "        del label\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # y_pred\n",
    "        label_pred_test = model(data_map_reshaped)\n",
    "\n",
    "        # confusion matrix\n",
    "        predict_labels = torch.cat((predict_labels, label_pred_test.argmax(1)), dim=0)\n",
    "        true_labels = torch.cat((true_labels, label_int), dim=0)\n",
    "#         print(predict_labels)\n",
    "#         print(true_labels)\n",
    "#         predict_labels = torch.tensor([predict_labels,label_pred_test.argmax(1)[0]])\n",
    "#         true_labels = torch.tensor([true_labels,label_int])\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(label_pred_test,label_int)\n",
    "        total_test_loss = total_test_loss + loss.item()\n",
    "        accuracy = ((label_pred_test.argmax(1)) == label_int).sum()\n",
    "        if label_int == 0:\n",
    "            total_acc_hc = total_acc_hc + accuracy\n",
    "            hc_count = hc_count + 1\n",
    "        elif label_int == 1:\n",
    "            total_acc_mcs = total_acc_mcs + accuracy\n",
    "            mcs_count = mcs_count + 1\n",
    "        elif label_int == 2:\n",
    "            total_acc_uws = total_acc_uws + accuracy\n",
    "            uws_count = uws_count + 1\n",
    "        if test_count % 20 == 0:\n",
    "            print(f\"共{test_count}组，准确{total_acc_hc+total_acc_mcs+total_acc_uws}个\")\n",
    "            print(f\"    HC:{total_acc_hc}个, MCS:{total_acc_mcs}个，UWS:{total_acc_uws}个\")\n",
    "            print(f\"准确率:{(total_acc_hc+total_acc_mcs+total_acc_uws) / test_count}\")\n",
    "            print(f\"    HC:{total_acc_hc/hc_count}, MCS:{total_acc_mcs/mcs_count}，UWS:{total_acc_uws/uws_count}\")\n",
    "    print(f\"共{test_count}组，准确{total_acc_hc+total_acc_mcs+total_acc_uws}个\")\n",
    "    print(f\"    HC:{total_acc_hc}个, MCS:{total_acc_mcs}个，UWS:{total_acc_uws}个\")\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"整体测试集上的Loss: {total_test_loss}\")\n",
    "    print(f\"整体测试集上的准确率: {(total_acc_hc+total_acc_mcs+total_acc_uws) / test_count}\")\n",
    "    print(f\"hc准确率: {total_acc_hc / hc_count}\")\n",
    "    print(f\"mcs准确率: {total_acc_mcs / mcs_count}\")\n",
    "    print(f\"uws准确率: {total_acc_uws / uws_count}\")\n",
    "    # writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    # writer.add_scalar(\"test_accuracy\", total_accuracy / test_data_size, total_test_step)\n",
    "    # total_test_step = total_test_step + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff460a4",
   "metadata": {},
   "source": [
    "# Draw Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed226ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ConditionB\n",
    "# model.load_state_dict(torch.load(f\"../model/{exper_dir}/Fold3_Epoch19.pt\")) # !!!!!!!!!!!!!!!!!!!!!\n",
    "# model.load_state_dict(torch.load(f\"../model/{exper_dir}/Fold4_Epoch11.pt\"))\n",
    "\n",
    "# ConditionC\n",
    "# model.load_state_dict(torch.load(f\"../model/{exper_dir}/Fold0_Epoch19.pt\"))\n",
    "# model.load_state_dict(torch.load(f\"../model/{exper_dir}/Fold1_Epoch28.pt\"))\n",
    "# model.load_state_dict(torch.load(f\"../model/{exper_dir}/Fold2_Epoch27.pt\"))\n",
    "# model.load_state_dict(torch.load(f\"../model/{exper_dir}/Fold3_Epoch50.pt\"))\n",
    "# 假设有模型的预测结果和真实标签\n",
    "#例如，假设模型预测的结果存储在名为 predicted_labels 的张量中，\n",
    "# 真实标签存储在名为 true_labels 的张量中\n",
    "# predicted_labels = torch.tensor([0, 1, 2, 1, 0, 2])\n",
    "# true_labels = torch.tensor([0, 1, 2, 1, 0, 1])\n",
    "\n",
    "# 将张量转换为 NumPy 数组\n",
    "predict_labels = predict_labels.cpu().numpy()\n",
    "true_labels = true_labels.cpu().numpy()\n",
    "\n",
    "# 计算混淆矩阵\n",
    "conf_matrix = confusion_matrix(true_labels, predict_labels)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "# 标记轴和标签\n",
    "classes = ['HC', 'MCS', 'UWS']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# 添加数值标签\n",
    "thresh = conf_matrix.max() / 2.\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13bd914",
   "metadata": {},
   "outputs": [],
   "source": [
    "del predict_labels\n",
    "del true_labels\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a78a4707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 565,  234, 1112,  173,  194,  389,  455,  114, 1133,  160,  380,  452,\n",
      "         774,   86,  473,    2, 1191, 1152,   62,  354,  313,  619,  793,  487,\n",
      "         936,  217,  226,  271,  443,   55, 1159,  408,  753,  350,  284,  680,\n",
      "         535, 1045, 1172,  439,  874,  734,  168,  768,  661,  386,  777,  858,\n",
      "        1043,  857,  645,   29, 1033,  610,  190,  495,  986,  841,  449,   32,\n",
      "        1218,  362, 1103,  108,  738,   38,  567,  534, 1020,  884,  180, 1186,\n",
      "          48,  721,  907,  254,  464,  555,  531, 1151,  704,  425,  163,  918,\n",
      "         556,  537, 1091,  961,  929, 1134,  878,  581,  909,  149,  317,  905,\n",
      "         352,  188,  401,  323, 1138,  393, 1058,  356,  112,  144,  300,  891,\n",
      "         722,  990, 1014,  795,  447, 1198, 1062,  337, 1197,  673,  546,   14,\n",
      "         959,   44,  713])\n",
      "tensor([1230,  753, 1259,  797,  294,  721,  651, 1088,  883,  503, 1143,  220,\n",
      "        1191,  129,  572, 1180,  619, 1215,  233,  210,  639,  575,  385,  499,\n",
      "        1321,  387,  122,  494, 1043,  587,  207, 1287,  528,   41, 1105,  569,\n",
      "        1330,  414, 1351, 1091, 1265,  589, 1247, 1343,  275, 1077, 1320,  771,\n",
      "        1052,  754,  960,  683,  801,  967,  590, 1007, 1283,  335,  410,  415,\n",
      "         798,  203,  226,  141,  897,  694,  376,  279,  379, 1084, 1344,  206,\n",
      "        1190,  344,  320,  736,  125, 1009,   35,  488,  227, 1030,  189, 1158,\n",
      "         671,  765,  239,  305,  713, 1071, 1335,   98, 1070,  689,  614, 1306,\n",
      "         316,  154,  867,  161,   72, 1086, 1073, 1003, 1204, 1311,   94, 1231,\n",
      "         580, 1233, 1202,  899,  959, 1220,  624, 1324, 1296,  878,  523,  756,\n",
      "         711,  490,  170,  669,  416,  999,  934,  340,  166, 1178,  431,  789,\n",
      "         894, 1312,  192])\n",
      "tensor([ 451,  309,  988,  683, 1115,  835,  636,  473,   63, 1095,  926, 1113,\n",
      "         382,  888,  334,  697,  818,   31,  595, 1166,  981,  301,  235,  939,\n",
      "         245,  708,  167,  203,  471,  383,   64,  844, 1046,  117,  994,  661,\n",
      "         655, 1007,  269,  606,  488,  177,  634, 1006,  455, 1026,  627,  748,\n",
      "        1058,  838,  405,  468, 1139, 1027,  984,  855,  869,  704,  544,  331,\n",
      "         831, 1031,  802,  560,  876,  550,  622,  644,  339, 1121,  541,  333,\n",
      "         412,   41,  618, 1055,  118,  631, 1054,  972,  749,  793, 1003,  621,\n",
      "          34,  479, 1163,  806,  273,  351,  800,  495,  670,  325, 1062,  832,\n",
      "         142,  266,  119,  464,  989, 1091,    9,  534,  459,  138,  769,  762,\n",
      "         633,   62,  771,  196, 1190,  390,  121,  342,  530,   80,  701,  937,\n",
      "         570, 1079])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "hc = torch.zeros([1231,1])\n",
    "mcs = torch.zeros([1353,1])\n",
    "uws = torch.zeros([1220,1])\n",
    "# test dataset\n",
    "# 生成随机种子\n",
    "torch.manual_seed(32)\n",
    "# 生成随机索引\n",
    "hc_indices = torch.randperm(len(hc))\n",
    "mcs_indices = torch.randperm(len(mcs))\n",
    "uws_indices = torch.randperm(len(uws))\n",
    "test_percentage = 0.1\n",
    "test_end = int(test_percentage * len(hc))\n",
    "test_hc_indices = hc_indices[:test_end]\n",
    "test_end = int(test_percentage * len(mcs))\n",
    "test_mcs_indices = mcs_indices[:test_end]\n",
    "test_end = int(test_percentage * len(uws))\n",
    "test_uws_indices = uws_indices[:test_end]\n",
    "print(test_hc_indices)\n",
    "print(test_mcs_indices)\n",
    "print(test_uws_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe602472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
