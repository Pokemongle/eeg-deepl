{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3f61f3",
   "metadata": {},
   "source": [
    "# 1. Necessary Headfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c52b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from load_data import MyData  # self-made\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm_notebook as tqdm # View procedure\n",
    "import os\n",
    "import scipy.io\n",
    "from random import random\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5816388",
   "metadata": {},
   "source": [
    "# 2. Prepare Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090b583",
   "metadata": {},
   "source": [
    "## 2.1. Navigate to the data folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f8e389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../eegdata\"\n",
    "# experimental dir: rest, conditionA, conditionB, conditionC\n",
    "exper_dir = \"conditionA\"\n",
    "# condition_dir: hc, mcs, uws\n",
    "condi_dir = \"hc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9897a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution index matrix\n",
    "matrix_index = np.array([\n",
    "    [0,0,2,2,4,4,6,6,8,8,2,2,4,4,6,6,2,4,6,3,3,5,5,3,3,5,5,3,3,2,2,4,4,6,6,1,1,3,3,5,5,7,7,2,2,4,4,6,6,1,1,3,3,5,5,7,7,0,5],\n",
    "    [4,6,3,7,3,7,3,7,4,6,1,9,1,9,1,9,5,5,5,4,6,4,6,2,8,2,8,0,10,4,6,4,6,4,6,4,6,3,7,3,7,4,6,2,8,2,8,2,8,3,7,1,9,1,9,3,7,5,5]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc60b2",
   "metadata": {},
   "source": [
    "## 2.2. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce555401",
   "metadata": {},
   "source": [
    "Change 59*1 sequence to 10*11 map and save the data into files\n",
    "Tips:\n",
    "    -Initialize a blank list to store the torch data\n",
    "    -Then use torch.stack(LIST) to change the data type into torch\n",
    "    -Finally use torch.save(data, filename) to save the torch data\n",
    "    -Check the list size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1db74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7f05b73df84c0ab508a7d58ea0a1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----现在处理：hc1.set.mat，共61段----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271162609b694cf5981542e068388083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "----现在处理：hc10.set.mat，共62段----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d0b730a6d049409581a520e8caa152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "----现在处理：hc11.set.mat，共58段----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c005e1258464d19898d349c2e498946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# 设置使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = MyData(root_dir, exper_dir, condi_dir) # eg.conditionA\\hc\n",
    "\n",
    "for person in tqdm(range(len(dataset))): #12种情况中的1种，其中的所有被试\n",
    "    # filepath是最子文件夹中每个.mat文件的名字\n",
    "    # path是包含当前情况的.mat文件的子文件夹\n",
    "    filename = os.path.join(dataset.path, dataset.file_path[person]) # eg. conditionA\\hc\\hc1.set.mat\n",
    "    data = scipy.io.loadmat(filename) # 读取该被试的数据为字典\n",
    "    data = data['datas'] # 键值对读取59*x的数据矩阵\n",
    "    # 将数据移动到GPU上\n",
    "    data = torch.from_numpy(data).to(device)\n",
    "    \n",
    "    # 在GPU上处理数据\n",
    "    # 创建被试全0map\n",
    "    data_map_person = []\n",
    "    print(f\"----现在处理：{dataset.file_path[person]}，共{data.shape[2]}段----\")\n",
    "    # 遍历该被试的所有段\n",
    "    for para in tqdm(range(data.shape[2])): \n",
    "        # 创建段全0map\n",
    "        data_map_para = [] \n",
    "        for point in range(data.shape[1]): # 遍历该段所有数据点\n",
    "            # 创建单个数据点全0map\n",
    "            data_map_point = torch.zeros((10, 11), device=device) \n",
    "            # 遍历59电极数据并赋值给全0map\n",
    "            for channel in range(data.shape[0]): \n",
    "                data_map_point[matrix_index[0][channel]][matrix_index[1][channel]] = data[channel][point][para]\n",
    "            # 保存单个数据点map到段map列表\n",
    "            data_map_para.append(data_map_point)\n",
    "        # 保存 段map 到 被试map\n",
    "        data_map_person.append(torch.stack(data_map_para))\n",
    "        print(len(data_map_person))\n",
    "        # 清理内存\n",
    "        del data_map_para\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    # 保存 被试map 到文件中\n",
    "    save_path = f\"..\\eegmap_direct\\conditionA\\hc\\{dataset.file_path[person]}.pt\"\n",
    "    torch.save(torch.stack(data_map_person), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a424334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "61\n",
      "2400\n",
      "10\n",
      "11\n",
      "<class 'list'>\n",
      "hc1.set.mat\n"
     ]
    }
   ],
   "source": [
    "print(len(data_map_all))\n",
    "print(len(data_map_all[0]))\n",
    "print(len(data_map_all[0][0]))\n",
    "print(len(data_map_all[0][0][0]))\n",
    "print(len(data_map_all[0][0][0][0]))\n",
    "print(type(data_map_all[0][0]))\n",
    "print(dataset.file_path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789e16d",
   "metadata": {},
   "source": [
    "## 2.3 Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "211d036e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-940fbb7e4346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_map_all\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'..\\eegmap_direct\\conditionA\\A_hc.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;31m# .cpu() on the underlying Storage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m         \u001b[1;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\storage.py\u001b[0m in \u001b[0;36mcpu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;34m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mtype\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;31m# or on typing_extensions module on Python >= 3.6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[0m__new__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_type\u001b[1;34m(self, dtype, non_blocking, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.save(data_map_all,'..\\eegmap_direct\\conditionA\\A_hc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aedf24c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[5. 6.]\n",
      "  [7. 8.]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mat_a = np.array([\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8]\n",
    "])\n",
    "mat_index = np.array([\n",
    "    [0,0,1,1],\n",
    "    [0,1,0,1]\n",
    "])\n",
    "\n",
    "keep_map = None\n",
    "\n",
    "for j in range(mat_a.shape[0]):\n",
    "    map = np.zeros((2,2))\n",
    "    for i in range(mat_a.shape[1]):\n",
    "        map[mat_index[0][i]][mat_index[1][i]] = mat_a[j][i]\n",
    "    if keep_map is None:\n",
    "        keep_map = map[np.newaxis, ...]\n",
    "    else:\n",
    "        keep_map = np.concatenate((keep_map, map[np.newaxis, ...]), axis=0)\n",
    "\n",
    "print(keep_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1ff8d135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 6.]\n",
      " [7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "print(keep_map[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
