{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089503e4",
   "metadata": {},
   "source": [
    "# Head Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0232fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from load_data import MyData  # self-made\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm_notebook as tqdm # View procedure\n",
    "import os\n",
    "import scipy.io\n",
    "from random import random\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from net_cnn_lstm1 import MyNetwork\n",
    "# from torchnlp.word_to_vector import GloVe\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4cde12",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8e967",
   "metadata": {},
   "source": [
    "## 设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0a7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "C,H,W = 1,1,2400\n",
    "learn_rate = 0.0005\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c43a00",
   "metadata": {},
   "source": [
    "## 设置随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92d241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "manualSeed = 32\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729b68e",
   "metadata": {},
   "source": [
    "## 设置优化器和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682c2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda:0\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ==损失函数权重\n",
    "# ======== 二分类HC/DOC\n",
    "# 计算总样本数量\n",
    "# condition1\n",
    "# total_samples = 887 + 985 + 879\n",
    "# condition2\n",
    "# total_samples = 929 + 1029 + 886\n",
    "# condition3\n",
    "# total_samples = 887 + 975 + 879\n",
    "# rest\n",
    "total_samples = 852 + 1051 + 872\n",
    "# 计算每个类别的权重\n",
    "# condition1\n",
    "# weights = [total_samples / 887, total_samples / (985 + 879)]\n",
    "# condition2\n",
    "# weights = [total_samples / 929, total_samples / (1029 + 886)]\n",
    "# condition3\n",
    "weights = [total_samples / 852, total_samples / (1051 + 872)]\n",
    "\n",
    "# ======== 二分类MCS/UWS\n",
    "# 计算总样本数量\n",
    "# condition1\n",
    "# total_samples = 985 + 879\n",
    "# condition2\n",
    "# total_samples = 1029 + 886\n",
    "# condition3\n",
    "# total_samples = 975 + 879\n",
    "# rest\n",
    "# total_samples = 1051 + 872\n",
    "# 计算每个类别的权重\n",
    "# condition1\n",
    "# weights = [total_samples / 985, total_samples / 879]\n",
    "# condition2\n",
    "# weights = [total_samples / 1029, total_samples / 886]\n",
    "# condition3\n",
    "# weights = [total_samples / 975, total_samples / 879]\n",
    "# condition3\n",
    "# weights = [total_samples / 1051, total_samples / 872]\n",
    "# 将权重转换为张量\n",
    "weights_tensor = torch.tensor(weights, device=device)\n",
    "\n",
    "# 定义交叉熵损失函数并设置权重\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d9378",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66243e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:96: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9060750d48c4ee990c9f999197bfec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/eegmap_split/rest\\train\\hc\\rest_hc_train_0.pt\n",
      "../data/eegmap_split/rest\\train\\hc\\rest_hc_train_0_hc_doc_label.pt\n",
      "../data/eegmap_split/rest\\test\\hc\\rest_hc_test_0.pt\n",
      "../data/eegmap_split/rest\\test\\hc\\rest_hc_test_0_hc_doc_label.pt\n",
      "../data/eegmap_split/rest\\train\\mcs\\rest_mcs_train_0.pt\n",
      "../data/eegmap_split/rest\\train\\mcs\\rest_mcs_train_0_hc_doc_label.pt\n",
      "../data/eegmap_split/rest\\test\\mcs\\rest_mcs_test_0.pt\n",
      "../data/eegmap_split/rest\\test\\mcs\\rest_mcs_test_0_hc_doc_label.pt\n",
      "../data/eegmap_split/rest\\train\\uws\\rest_uws_train_0.pt\n",
      "../data/eegmap_split/rest\\train\\uws\\rest_uws_train_0_hc_doc_label.pt\n",
      "../data/eegmap_split/rest\\test\\uws\\rest_uws_test_0.pt\n",
      "../data/eegmap_split/rest\\test\\uws\\rest_uws_test_0_hc_doc_label.pt\n",
      "torch.Size([2221, 2400, 10, 11])\n",
      "torch.Size([2221])\n",
      "torch.Size([554, 2400, 10, 11])\n",
      "torch.Size([554])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:159: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3064031d9b304fb4959b405bf74c7995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 0 Training =========\n",
      "tensor([[-2.0111,  1.8303]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 155.15571403503418\n",
      "Train steps: 1000, Loss: 0.021236183121800423\n",
      "tensor([[-1.1833,  0.9706]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 307.1384265422821\n",
      "Train steps: 2000, Loss: 0.10978776961565018\n",
      "========= Epoch 0 Testing =========\n",
      "Loss: 33.67145538330078 Accuracy: 0.8399999737739563\n",
      "Loss: 62.415245056152344 Accuracy: 0.85999995470047\n",
      "Loss: 89.17206573486328 Accuracy: 0.8733333349227905\n",
      "Loss: 120.63370513916016 Accuracy: 0.8700000047683716\n",
      "Loss: 158.4302978515625 Accuracy: 0.8660000562667847\n",
      "Total Loss: 174.84486389160156 Total Accuracy: 0.8682310581207275\n",
      "..........Saving the model..........\n",
      "========= Epoch 1 Training =========\n",
      "tensor([[-1.9829,  1.7046]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 535.0118744373322\n",
      "Train steps: 3000, Loss: 0.024726662784814835\n",
      "tensor([[ 0.6625, -0.5796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 688.022871017456\n",
      "Train steps: 4000, Loss: 0.25369176268577576\n",
      "========= Epoch 1 Testing =========\n",
      "Loss: 28.194416046142578 Accuracy: 0.8499999642372131\n",
      "Loss: 56.26958084106445 Accuracy: 0.8549999594688416\n",
      "Loss: 82.62419128417969 Accuracy: 0.8700000047683716\n",
      "Loss: 105.84602355957031 Accuracy: 0.8700000047683716\n",
      "Loss: 133.75096130371094 Accuracy: 0.8660000562667847\n",
      "Total Loss: 161.11715698242188 Total Accuracy: 0.8610108494758606\n",
      "..........Saving the model..........\n",
      "========= Epoch 2 Training =========\n",
      "tensor([[-3.5390,  3.3283]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 909.4130074977875\n",
      "Train steps: 5000, Loss: 0.0010407513473182917\n",
      "tensor([[-2.0374,  1.8341]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1063.1557140350342\n",
      "Train steps: 6000, Loss: 0.020614655688405037\n",
      "========= Epoch 2 Testing =========\n",
      "Loss: 51.80556869506836 Accuracy: 0.8999999761581421\n",
      "Loss: 104.18563842773438 Accuracy: 0.8799999952316284\n",
      "Loss: 134.042724609375 Accuracy: 0.893333375453949\n",
      "Loss: 170.46661376953125 Accuracy: 0.8999999761581421\n",
      "Loss: 234.981201171875 Accuracy: 0.89000004529953\n",
      "Total Loss: 264.1252746582031 Total Accuracy: 0.8880866169929504\n",
      "..........Saving the model..........\n",
      "========= Epoch 3 Training =========\n",
      "tensor([[-2.8965,  2.7662]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1281.929486989975\n",
      "Train steps: 7000, Loss: 0.0034671451430767775\n",
      "tensor([[ 0.3077, -0.1362]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1437.0211889743805\n",
      "Train steps: 8000, Loss: 0.49563083052635193\n",
      "========= Epoch 3 Testing =========\n",
      "Loss: 5.081418991088867 Accuracy: 0.9699999690055847\n",
      "Loss: 17.661231994628906 Accuracy: 0.949999988079071\n",
      "Loss: 24.168264389038086 Accuracy: 0.9633333683013916\n",
      "Loss: 39.49230194091797 Accuracy: 0.9574999809265137\n",
      "Loss: 49.585994720458984 Accuracy: 0.9540000557899475\n",
      "Total Loss: 52.88059616088867 Total Accuracy: 0.9548736214637756\n",
      "..........Saving the model..........\n",
      "========= Epoch 4 Training =========\n",
      "tensor([[ 4.0803, -3.9442]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1654.9392783641815\n",
      "Train steps: 9000, Loss: 0.00032729512895457447\n",
      "tensor([[-3.6756,  3.4713]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1808.0637500286102\n",
      "Train steps: 10000, Loss: 0.0007870674598962069\n",
      "tensor([[-2.7125,  2.4296]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 1962.387508392334\n",
      "Train steps: 11000, Loss: 0.005828646942973137\n",
      "========= Epoch 4 Testing =========\n",
      "Loss: 15.168445587158203 Accuracy: 0.9399999976158142\n",
      "Loss: 26.45231819152832 Accuracy: 0.9449999928474426\n",
      "Loss: 29.827911376953125 Accuracy: 0.9566667079925537\n",
      "Loss: 36.82909393310547 Accuracy: 0.9624999761581421\n",
      "Loss: 42.22511291503906 Accuracy: 0.9660000205039978\n",
      "Total Loss: 44.819496154785156 Total Accuracy: 0.9675090312957764\n",
      "..........Saving the model..........\n",
      "========= Epoch 5 Training =========\n",
      "tensor([[-5.0718,  4.9889]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2183.3767490386963\n",
      "Train steps: 12000, Loss: 4.267601980245672e-05\n",
      "tensor([[-5.4386,  5.3510]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2337.8832669258118\n",
      "Train steps: 13000, Loss: 2.062299427052494e-05\n",
      "========= Epoch 5 Testing =========\n",
      "Loss: 15.527033805847168 Accuracy: 0.949999988079071\n",
      "Loss: 25.383920669555664 Accuracy: 0.9649999737739563\n",
      "Loss: 32.309600830078125 Accuracy: 0.9666666984558105\n",
      "Loss: 37.27296447753906 Accuracy: 0.9699999690055847\n",
      "Loss: 45.75673294067383 Accuracy: 0.968000054359436\n",
      "Total Loss: 53.70689392089844 Total Accuracy: 0.9657039642333984\n",
      "..........Saving the model..........\n",
      "========= Epoch 6 Training =========\n",
      "tensor([[-3.3785,  2.9951]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2554.734034061432\n",
      "Train steps: 14000, Loss: 0.0017045505810528994\n",
      "tensor([[-4.4293,  4.0797]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2708.508336544037\n",
      "Train steps: 15000, Loss: 0.00020168177434243262\n",
      "========= Epoch 6 Testing =========\n",
      "Loss: 40.20013427734375 Accuracy: 0.8899999856948853\n",
      "Loss: 72.51229858398438 Accuracy: 0.9149999618530273\n",
      "Loss: 91.10975646972656 Accuracy: 0.9300000071525574\n",
      "Loss: 122.2037582397461 Accuracy: 0.9300000071525574\n",
      "Loss: 159.92066955566406 Accuracy: 0.9240000247955322\n",
      "Total Loss: 170.24710083007812 Total Accuracy: 0.9241877198219299\n",
      "..........Saving the model..........\n",
      "========= Epoch 7 Training =========\n",
      "tensor([[-4.6002,  4.2451]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 2930.769383907318\n",
      "Train steps: 16000, Loss: 0.00014399446081370115\n",
      "tensor([[-4.9595,  4.5982]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3085.781592607498\n",
      "Train steps: 17000, Loss: 7.068861305015162e-05\n",
      "========= Epoch 7 Testing =========\n",
      "Loss: 26.22981071472168 Accuracy: 0.949999988079071\n",
      "Loss: 56.11039352416992 Accuracy: 0.9399999976158142\n",
      "Loss: 116.93888854980469 Accuracy: 0.9233333468437195\n",
      "Loss: 138.9822998046875 Accuracy: 0.9325000047683716\n",
      "Loss: 196.8050537109375 Accuracy: 0.9280000329017639\n",
      "Total Loss: 226.50430297851562 Total Accuracy: 0.9277978539466858\n",
      "..........Saving the model..........\n",
      "========= Epoch 8 Training =========\n",
      "tensor([[-4.3551,  4.0229]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Train time: 3274.8168847560883\n",
      "Train steps: 18000, Loss: 0.00022980909852776676\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(dataset,mode):\n",
    "    # find the fold file\n",
    "    count = 0\n",
    "    for person in range(len(dataset)):\n",
    "        filename = os.path.join(dataset.path, dataset.file_path[person])\n",
    "        # extract the pure name of the file\n",
    "        parts = filename.split(\"\\\\\")\n",
    "        file_name = parts[-1]\n",
    "        name_without_extension = file_name.split(\".\")[0]\n",
    "        # label or data\n",
    "        file_last = name_without_extension.split(\"_\")[-1]\n",
    "        if file_last.isdigit(): # data\n",
    "            # is this fold or not\n",
    "            if int(file_last) == fold: # yes\n",
    "                print(filename)\n",
    "                count = count + 1\n",
    "                data_map = torch.load(filename)\n",
    "                # train or test\n",
    "                if name_without_extension.split(\"_\")[-2] == \"train\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        train_data.append(data_map[i])\n",
    "                elif name_without_extension.split(\"_\")[-2] == \"test\":\n",
    "                    for i in range(data_map.size(0)):\n",
    "                        test_data.append(data_map[i])\n",
    "                if count == 4:\n",
    "                    del data_map\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache() \n",
    "                    break\n",
    "            else:   # not\n",
    "                pass\n",
    "        else: # label\n",
    "            file_last = name_without_extension.split(\"_\")[-4]\n",
    "            file_mode = name_without_extension.split(\"_\")[-2]\n",
    "            if file_mode == mode.split(\"_\")[-1]: # is this mode or not\n",
    "                # is this fold or not\n",
    "                if int(file_last) == fold: # yes\n",
    "                    print(filename)\n",
    "                    count = count + 1\n",
    "                    data_map = torch.load(filename)\n",
    "                    # train or test\n",
    "                    if name_without_extension.split(\"_\")[-5] == \"train\":\n",
    "                        for i in range(data_map.size(0)):\n",
    "                            train_label.append(data_map[i])\n",
    "                    elif name_without_extension.split(\"_\")[-5] == \"test\":\n",
    "                        for i in range(data_map.size(0)):\n",
    "                            test_label.append(data_map[i])\n",
    "                    if count == 4:\n",
    "                        del data_map\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache() \n",
    "                        break\n",
    "                else:   # not\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        del filename, parts, file_name, name_without_extension, file_last\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()    \n",
    "# 定义LSTM超参数\n",
    "input_size = 64  # 输入特征维度\n",
    "hidden_size = 64  # 隐藏单元数量\n",
    "num_layers = 2  # LSTM层数\n",
    "output_size = 2  # 输出类别数量\n",
    "# 创建模型实例\n",
    "# model_list = ['', '_CNN', '_CNN_spa', '_CNN_spa_lstm']\n",
    "# model_name = model_list[0]\n",
    "# if model_name == model_list[0]: #  CascadeCept\n",
    "#     from network_cnn_lstm import MyNetwork\n",
    "# elif model_name == model_list[1]: #  CNN\n",
    "#     from network_cnn_lstm_2 import MyNetwork\n",
    "# elif model_name == model_list[2]: # CascadeCept_1\n",
    "#     from network_cnn_lstm_3 import MyNetwork\n",
    "# elif model_name == model_list[3]: # CascadeCept_2\n",
    "#     from network_cnn_lstm_4 import MyNetwork\n",
    "model_list = ['_1', '_2', '_3', '_4', '_5']\n",
    "model_name = model_list[5]\n",
    "if model_name == model_list[0]: \n",
    "    from net_cnn_lstm1 import MyNetwork\n",
    "elif model_name == model_list[1]: \n",
    "    from net_cnn_lstm2 import MyNetwork\n",
    "elif model_name == model_list[2]: \n",
    "    from net_cnn_lstm3 import MyNetwork\n",
    "elif model_name == model_list[3]: \n",
    "    from net_cnn_lstm4 import MyNetwork\n",
    "elif model_name == model_list[4]: \n",
    "    from net_cnn_lstm5 import MyNetwork\n",
    "\n",
    "model = MyNetwork(input_size, hidden_size, num_layers, output_size)\n",
    "model = model.to(device)\n",
    "\n",
    "# experimental dir: rest, conditionA, conditionB, conditionC\n",
    "exper_dir = \"rest\"\n",
    "root_dir = f\"../data/eegmap_split/{exper_dir}\"\n",
    "# classification = \"hc_doc\"/doc or \"mcs_uws\"/uws\n",
    "classification = \"hc_doc\"\n",
    "# classification = \"mcs_uws\"\n",
    "fold_num = 5\n",
    "for fold in tqdm(range(5)):\n",
    "    # train num folds\n",
    "#     fold = 0 # 选择折数\n",
    "    # -- prepare datasets\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    \n",
    "    if classification == \"hc_doc\":\n",
    "        # ---- hc\n",
    "        dataset = MyData(root_dir, \"train\", \"hc\") # hc\n",
    "        make_dataset(dataset,classification)\n",
    "        dataset = MyData(root_dir, \"test\", \"hc\") # hc\n",
    "        make_dataset(dataset,classification)\n",
    "    # ---- mcs\n",
    "    dataset = MyData(root_dir, \"train\", \"mcs\") # mcs\n",
    "    make_dataset(dataset,classification)\n",
    "    dataset = MyData(root_dir, \"test\", \"mcs\") # hc\n",
    "    make_dataset(dataset,classification)\n",
    "    # ---- uws\n",
    "    dataset = MyData(root_dir, \"train\", \"uws\") # uws\n",
    "    make_dataset(dataset,classification)\n",
    "    dataset = MyData(root_dir, \"test\", \"uws\") # hc\n",
    "    make_dataset(dataset,classification)\n",
    "    \n",
    "    print(torch.stack(train_data).size())\n",
    "    print(torch.stack(train_label).size())\n",
    "    print(torch.stack(test_data).size())\n",
    "    print(torch.stack(test_label).size())\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "    \n",
    "    train_data = torch.stack(train_data)\n",
    "    train_label = torch.stack(train_label)\n",
    "    test_data = torch.stack(test_data)\n",
    "    test_label = torch.stack(test_label)\n",
    "    # train dataset\n",
    "    train_td = TensorDataset(train_data, train_label)\n",
    "    train_loader = DataLoader(train_td, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    # test dataset\n",
    "    test_td = TensorDataset(test_data, test_label)\n",
    "    test_loader = DataLoader(test_td, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    del train_data, train_label, test_data, test_label, train_td, test_td\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # set model for each fold\n",
    "    model = MyNetwork(input_size, hidden_size, num_layers, output_size)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learn_rate)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 30, 50], gamma=0.2)\n",
    "    # -- start training\n",
    "    start_time = time.time()\n",
    "    # train and test step records\n",
    "    total_train_step = 0\n",
    "    total_test_step = 0\n",
    "    min_test_loss = 1000\n",
    "    # add Tensorboard\n",
    "    writer_train = SummaryWriter(f\"../logs/{classification}/{exper_dir}{model_name}/logs_train_{fold}\")\n",
    "    writer_valid = SummaryWriter(f\"../logs/{classification}/{exper_dir}{model_name}/logs_test_{fold}\")\n",
    "    writer_valid_acc = SummaryWriter(f\"../logs/{classification}/{exper_dir}{model_name}/logs_test_acc_{fold}\")\n",
    "    for i in tqdm(range(num_epochs)):  \n",
    "        print(f\"========= Epoch {i} Training =========\")\n",
    "        # train steps\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            # x, y\n",
    "            data_map, label=data\n",
    "            data_map_reshaped = torch.reshape(data_map, (110, 1, 1, 2400))\n",
    "            label_int = label.long()\n",
    "            data_map_reshaped=data_map_reshaped.to(device)\n",
    "            label_int=label_int.to(device)\n",
    "            del data_map, label\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # y_pred\n",
    "            label_pred = model(data_map_reshaped)\n",
    "            # Loss Computation and Optimization\n",
    "            loss = criterion(label_pred,label_int)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # draw tensorboard\n",
    "            total_train_step = total_train_step + 1\n",
    "            # print info\n",
    "            if total_train_step % 1000 == 0:\n",
    "                end_time = time.time()\n",
    "                print(label_pred)\n",
    "                print(f\"Train time: {end_time - start_time}\")\n",
    "                print(f\"Train steps: {total_train_step}, Loss: {loss.item()}\")\n",
    "            writer_train.add_scalar(\"train_loss\",loss.item(),total_train_step)\n",
    "            # Clear gpu\n",
    "            del data, data_map_reshaped, label_int, label_pred, loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Evaluation and save the best model\n",
    "        print(f\"========= Epoch {i} Testing =========\")\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        test_count = 0\n",
    "        total_test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                test_count = test_count + 1\n",
    "                # x, y\n",
    "                data_map, label=data\n",
    "                data_map_reshaped = torch.reshape(data_map, (110, 1, 1, 2400))\n",
    "                label_int = label.long()\n",
    "                data_map_reshaped = data_map_reshaped.to(device)\n",
    "                label_int = label_int.to(device)\n",
    "                del data_map, label\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                # y_pred\n",
    "                label_pred_test = model(data_map_reshaped)\n",
    "                loss = criterion(label_pred_test,label_int)\n",
    "#                 print(label_pred_test)\n",
    "                # accuracy \n",
    "                total_test_acc = total_test_acc + ((label_pred_test.argmax(1)) == label_int).sum()\n",
    "                # draw tensorboad\n",
    "                total_test_loss = total_test_loss + loss\n",
    "                if test_count % 100 == 0:\n",
    "                    print(f\"Loss: {total_test_loss} Accuracy: {total_test_acc/test_count}\")\n",
    "                # Clear gpu\n",
    "                del data_map_reshaped, label_int, label_pred_test, loss, data\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "        print(f\"Total Loss: {total_test_loss} Total Accuracy: {total_test_acc/test_count}\")\n",
    "        writer_valid.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "        writer_valid_acc.add_scalar(\"test_acc\", total_test_acc/test_count, total_test_step)\n",
    "        total_test_step = total_test_step + 1\n",
    "        print(\"..........Saving the model..........\")\n",
    "        torch.save(model.state_dict(),f\"../models/{classification}/{exper_dir}{model_name}/Fold{fold}_Epoch{i}.pt\") \n",
    "#         if total_test_loss < min_test_loss:\n",
    "#             min_test_loss = total_test_loss\n",
    "#             print(\"..........Saving the model..........\")\n",
    "#             torch.save(model.state_dict(),f\"../model/{exper_dir}/Fold{fold}_Epoch{i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2902e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
